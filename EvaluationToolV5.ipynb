{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c2e90503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version : 2.9.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "# import pyodbc\n",
    "import joblib\n",
    "from pandas import pivot_table\n",
    "from distutils.dir_util import copy_tree\n",
    "import shutil\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "from imageio import imsave\n",
    "from math import log10, floor,ceil\n",
    "from scipy.stats import linregress\n",
    "from sklearn.metrics import accuracy_score, f1_score, median_absolute_error,precision_score, recall_score, classification_report, confusion_matrix,mean_squared_error, r2_score\n",
    "import plotly.figure_factory as ff\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "# from wai.ma.core.matrix import Matrix, helper\n",
    "# from wai.ma.transformation import SavitzkyGolay2\n",
    "# from wai.ma.filter import Downsample\n",
    "from pathlib import Path\n",
    "print(f'tensorflow version : {tf.version.VERSION}')\n",
    "# tf.enable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# ClassifierKwargs = ClassifierKwargs()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbb378",
   "metadata": {},
   "source": [
    "# Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cebd5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chems(path_to_model,predction_folder_path, chemicals,model_versions, data ):\n",
    "    for model_version in model_versions:\n",
    "        \n",
    "        \n",
    "        print(f'Starting prediction using model version {model_version}')\n",
    "        base_path = Path(path_to_model)\n",
    "        for chemical in chemicals:\n",
    "            print(chemical)\n",
    "            preds_comb = pd.DataFrame()\n",
    "            models_folder = base_path / chemical / 'std'\n",
    "            all_models = [x for x in models_folder.glob('**/*.hdf5')]\n",
    "\n",
    "            #                             data = pd.read_csv(filename, index_col=[0,1])\n",
    "            data = data\n",
    "            new_indices = data.index\n",
    "            # data.drop(chemical, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "            for model_path in all_models:\n",
    "\n",
    "                json_path = model_path.parent.parent / 'model.json'\n",
    "\n",
    "                with open(json_path) as f:\n",
    "                    json_ = json.load(f)\n",
    "\n",
    "                inputs = []\n",
    "\n",
    "                for i in range(len(json_['Inputs'])):\n",
    "                    input_name = json_['Inputs'][i]['Name']\n",
    "#                     print(f'filename: {filename}')\n",
    "                    train = data.copy(deep=True)\n",
    "\n",
    "                    for j in range(len(json_['Inputs'][i]['Pre-processing'])):\n",
    "                        key_ = json_['Inputs'][i]['Pre-processing'][j]['Name']\n",
    "                        if input_name == 'nir2':\n",
    "                            input_name = 'nir.2'\n",
    "                            \n",
    "                        pickle_path = model_path.parent / 'preprocess' / f'input.{input_name}.{j}.{key_}.pickle'\n",
    "                        pickle_ = joblib.load(pickle_path)\n",
    "                        train = pickle_.fit_transform(train)\n",
    "\n",
    "                    inputs.append(train.values)\n",
    "\n",
    "                tf.keras.backend.clear_session()\n",
    "                model = tf.keras.models.load_model(model_path, compile=False)\n",
    "                preds = pd.DataFrame(model(inputs).numpy())\n",
    "                preds_comb = pd.concat([preds_comb, preds], axis=1)\n",
    "            preds_comb = preds_comb.median(axis=1)\n",
    "            preds_comb.index = new_indices\n",
    "\n",
    "            os.makedirs(f'{predction_folder_path}/{model_version}', exist_ok=True)\n",
    "            preds_comb.to_csv(f'{predction_folder_path}/{model_version}/{chemical}_preds.csv')\n",
    "        print(f'Finalizing prediction using model version {model_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1c6151f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_model = 'D://CropNutsDocuments/QC_Model Preds_2022-11-06/dl_models_all_chems_20210414/dl_v2.2_update_2022'\n",
    "# predction_folder_path = 'D://CropNutsDocuments/DS_ML113/outputFiles/preds'\n",
    "# chemicals = ['aluminium', \n",
    "#             'phosphorus', 'ph', 'exchangeable_acidity', 'calcium', 'magnesium',\n",
    "#               'sulphur', 'sodium', 'iron', 'manganese', 'boron', 'copper', 'zinc', 'total_nitrogen', 'potassium',\n",
    "#              'ec_salts', 'organic_carbon', 'cec', 'sand', 'silt', 'clay']\n",
    "# model_versions = ['DLv2.2']\n",
    "# data = pd.read_csv(\"D://CropNutsDocuments/DS_ML113/outputFiles/averaged_spectra.csv\", index_col=0)\n",
    "# data = data.drop(\"3977\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3f56e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_chems(path_to_model,predction_folder_path, chemicals,model_versions, data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c8c12c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_data(spc_data,path_to_codes_subset):\n",
    "    print(f'Subsetting data')\n",
    "    codes = pd.read_csv(path_to_codes_subset,index_col=0)\n",
    "    codes = codes.dropna()\n",
    "    codes = codes.drop_duplicates()\n",
    "    codes = codes.index\n",
    "    df = spc_data.reindex(codes)\n",
    "    df = df.drop_duplicates()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f2c1ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_preds_wet(path_to_wet, output_path ,model_versions, chemicals, predction_folder_path):\n",
    "    os.makedirs(Path(os.path.join(output_path)) / 'saved_models',exist_ok=True)\n",
    "    df = pd.read_csv(path_to_wet,index_col=0)\n",
    "    df.index = df.index.str.strip()\n",
    "    for chemical in chemicals:\n",
    "        df_ = df[chemical]\n",
    "        df_ = df_.to_frame()\n",
    "        df_ = df_.dropna()\n",
    "        \n",
    "        for model_version in model_versions:\n",
    "            print(f'Starting to join predictions and wetchem for evaluation for model version {model_version}')\n",
    "            print(f\"Prediction folder path {predction_folder_path}\")\n",
    "            df_preds = pd.read_csv(f'{predction_folder_path}/{model_version}/{chemical}_preds.csv', index_col=0,header=None)\n",
    "            \n",
    "            df_preds = df_preds.reindex(df_.index)\n",
    "            # df_preds = df_preds.dropna()\n",
    "            print(\"Preds\", df_preds)\n",
    "            df_preds = df_preds.rename(columns= {0:f'{model_version}_regression'})\n",
    "            print(\"Preds\",df_preds)\n",
    "            df_wet = df_.rename(columns= {chemical:'y_true_val'})\n",
    "            print(\"Wet\",df_wet)\n",
    "            comb_df = pd.concat([df_preds,df_wet],axis=1)\n",
    "            comb_df= comb_df.dropna()\n",
    "            comb_df = comb_df[~comb_df.index.duplicated()]\n",
    "            print(comb_df.shape)\n",
    "            \n",
    "            comb_df.to_csv(Path(os.path.join(output_path ,model_version)) / f'{chemical}_False_y_pred_list_df.csv' )\n",
    "            comb_df.to_pickle(Path(os.path.join(output_path))/ 'saved_models' / f'{chemical}_{model_version}_regression_False_score_trained.pkl' )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269594f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "658cf6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_diff_models_data(output_path ,model_versions, chemicals,name_of_subset):\n",
    "    \n",
    "    for chemical in chemicals:\n",
    "        print(f'Starting to join predictions and wetchem for evaluation for different models version for chemical {chemical}')\n",
    "        comb_df = pd.DataFrame()\n",
    "        for model_version in model_versions:\n",
    "            \n",
    "    \n",
    "            df = pd.read_csv(Path(os.path.join(output_path ,model_version)) / f'{chemical}_False_y_pred_list_df.csv',index_col=0 )\n",
    "            y_true_val_series = df['y_true_val']\n",
    "            comb_df = pd.concat([comb_df,df],axis=1)\n",
    "            comb_df = comb_df.drop(columns = ['y_true_val'])\n",
    "            comb_df.to_pickle(Path(os.path.join(output_path))/f'{name_of_subset}'/ 'saved_models' / f'{chemical}_{model_version}_regression_False_score_trained.pkl' )\n",
    "      \n",
    "        comb_df = pd.concat([y_true_val_series, comb_df],axis=1)\n",
    "        os.makedirs(os.path.join(output_path, f'{name_of_subset}','saved_models' ), exist_ok=True)\n",
    "        comb_df.to_csv(Path(output_path)/f'{name_of_subset}' /'saved_models' / f'{chemical}_False_y_pred_list_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "eb6beac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spectra(path_to_spectra):\n",
    "    spc_data = pd.read_csv(path_to_spectra,index_col=0, engine='c')\n",
    "    \n",
    "    return spc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49c5936",
   "metadata": {},
   "source": [
    "## Run the Evaluation Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a002c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationTool:\n",
    "   \n",
    "    def __init__(self, **kwargs: dict):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "        allowed_keys =[\"chemical\",\"out_path\", \"method\",\"method2\"]\n",
    "\n",
    "        self.__dict__.update((k,v) for k, v in kwargs.items() if k in allowed_keys)\n",
    "\n",
    "        if not hasattr(self, \"chemical\"):\n",
    "            self.chemical = \"ph\"\n",
    "        if not hasattr(self , \"out_path\"):\n",
    "            self.out_path = os.getcwd()\n",
    "            \n",
    "        if not hasattr(self, 'method'):\n",
    "            self.method = \"regression\"\n",
    "            \n",
    "        if not hasattr(self, 'method2'):\n",
    "            self.method2 = \"classification\"\n",
    "\n",
    "\n",
    "    #helper function to create new directory\n",
    "    @staticmethod\n",
    "    def _create_dir_if_not_exists(path):\n",
    "        import pathlib\n",
    "        pathlib.Path(os.path.dirname(path)).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    #Helper function to convert results to 3 significant figures\n",
    "    @staticmethod\n",
    "    def _round_sig(x, sig=3):\n",
    "        if x == 0: return 0\n",
    "        else: return round(x, sig-int(ceil(log10(abs(x))))-1)\n",
    "    \n",
    "    \n",
    "    def reversed_chemical_name(self, chemical):\n",
    "\n",
    "        if chemical == 'ec_salts': return 'ec'\n",
    "\n",
    "        elif chemical == 'exchangeable_acidity': return 'exchangeable'\n",
    "\n",
    "        elif chemical =='total_nitrogen': return 'total'\n",
    "\n",
    "        elif chemical == 'organic_carbon': return 'organic' \n",
    "        \n",
    "        elif chemical == 'reactive_carbon': return 'reactive' \n",
    "        \n",
    "        elif chemical == 'reactive_carbon': return 'reactive' \n",
    "        \n",
    "        elif chemical == 'phosphorus_olsen': return 'olsen' \n",
    "  \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        return chemical\n",
    "\n",
    "  \n",
    "    \n",
    "    def correct_chemical_name(self, chemical):\n",
    "\n",
    "        if chemical == 'ec':\n",
    "            index_= 2\n",
    "            chemical = 'ec_salts'\n",
    "        elif chemical == 'exchangeable':\n",
    "            chemical = 'exchangeable_acidity'\n",
    "            index_= 2\n",
    "        elif chemical == 'total':\n",
    "            chemical = 'total_nitrogen'\n",
    "            index_= 2\n",
    "        elif chemical == 'organic':\n",
    "            chemical ='organic_carbon'\n",
    "            index_= 2\n",
    "            \n",
    "        elif chemical == 'reactive':\n",
    "            \n",
    "            chemical ='reactive_carbon'\n",
    "            index_= 2\n",
    "            \n",
    "        elif chemical == 'phosphorus':\n",
    "            \n",
    "            \n",
    "            chemical ='phosphorus_olsen'\n",
    "            index_= 2\n",
    "\n",
    "        else:\n",
    "            index_= 1\n",
    "\n",
    "        return chemical , index_\n",
    "    def get_chem_model_map(self, training_pred_score_path, chemical):\n",
    "        models = []\n",
    "        original_path = os.path.join(training_pred_score_path , 'saved_models/')\n",
    "        #grab all lgb and xgb models since they have different extentions\n",
    "        delimeter = \"/*_regression_False_score_trained.pkl\"\n",
    "        path1 = glob.glob(original_path + delimeter)\n",
    "     \n",
    "        for path in path1:\n",
    "            if chemical in os.path.basename(path):\n",
    "                path_base = os.path.basename(path)\n",
    "                model = path_base.split('_')[-5]\n",
    "                models.append(model)\n",
    "        chem_model_map = {chemical: models}\n",
    "                \n",
    "            \n",
    "        return chem_model_map\n",
    "    \n",
    "    def _wetchem_statistics(self, df):\n",
    "\n",
    "        df2 = pd.DataFrame(columns=['no_samples','mean','median','sd','minimum','maximum','quantile_25','quantile_75','kurtosis','skew'], index=df.columns)\n",
    "        for chem in df.columns:\n",
    "            \n",
    "        \n",
    "            sd = df[chem].std()\n",
    "            minimum = df[chem].min()\n",
    "            kurtosis = df[chem].kurtosis()\n",
    "            skew = df[chem].skew()\n",
    "            maximum = df[chem].max()\n",
    "            mean=  df[chem].mean()\n",
    "            median = df[chem].median()\n",
    "            quantile_25 = df[chem].quantile(q=0.25)\n",
    "            quantile_75 = df[chem].quantile(q=0.75)\n",
    "            no_samples = len(df[chem].dropna())\n",
    "\n",
    "            df2.at[chem, 'no_samples'] = no_samples\n",
    "            if chem.endswith(\"regression\"):\n",
    "                pass\n",
    "            else:\n",
    "                df2.at[chem, 'minimum'] = self._round_sig(minimum)\n",
    "                df2.at[chem, 'maximum'] = self._round_sig(maximum)\n",
    "                df2.at[chem, 'quantile_25'] = self._round_sig(quantile_25)\n",
    "                df2.at[chem, 'quantile_75'] = self._round_sig(quantile_75)\n",
    "                df2.at[chem, 'kurtosis']= self._round_sig(kurtosis)\n",
    "                df2.at[chem, 'skew']  = self._round_sig(skew)\n",
    "                df2.at[chem, 'mean'] = self._round_sig(mean)\n",
    "                df2.at[chem, 'median'] = self._round_sig(median)\n",
    "                df2.at[chem, 'sd'] = self._round_sig(sd)\n",
    "\n",
    "        return df2\n",
    "    def ppm_to_percentage(self,cec_df, training_pred_score_path , df_perc, df, num_divider, chemical):\n",
    "        cec_models_trained = []\n",
    "        chemical_models_trained = []\n",
    "\n",
    "        for col in cec_df:\n",
    "            if col != 'y_true_val':\n",
    "                cec_df.rename(columns = {col: f'{col}_cec'}, inplace=True)\n",
    "                cec_models_trained.append(f'{col}_cec')\n",
    "\n",
    "\n",
    "\n",
    "        for col in df:\n",
    "            if col != 'y_true_val':\n",
    "                chemical_models_trained.append(col)\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col == 'y_true_val':\n",
    "\n",
    "                df_perc['y_true_val'] = ((df[col] / num_divider) / cec_df[col]) * 100\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "        cec_chemical_models_list = cec_models_trained + chemical_models_trained \n",
    "        combined_list = list(itertools.combinations(cec_chemical_models_list, 2))\n",
    "        combined_list = [list(i) for i in combined_list] # list of lists\n",
    "\n",
    "        for item in enumerate(combined_list):\n",
    "            if item[1][0].endswith('cec') and item[1][1].endswith('cec'):\n",
    "                combined_list.pop(item[0])\n",
    "\n",
    "            elif item[1][0].endswith('cec') or item[1][1].endswith('cec'):\n",
    "                pass\n",
    "            else:\n",
    "                combined_list.pop(item[0])\n",
    "#         combined_list.remove(combined_list[0])\n",
    "        print(combined_list)\n",
    "#         combined_list.remove(combined_list[-1])\n",
    "\n",
    "        writer = pd.ExcelWriter(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_%_False_y_pred_list_df.xlsx'))\n",
    "        \n",
    "        cec_list =[]\n",
    "        other_chem_list = []\n",
    "        for list_ in combined_list:\n",
    "            other_chem_list.append(list_[1])\n",
    "            cec_list.append(list_[0])\n",
    "      \n",
    "        per_model_data_dict ={}\n",
    "        for i in range(len(cec_list)):\n",
    "            \n",
    "            \n",
    "            per_model_data = ((df[other_chem_list[i]] / num_divider) / cec_df[cec_list[i]]) * 100\n",
    "            per_model_data_dict.update({other_chem_list[i]:per_model_data})\n",
    "            df_perc[other_chem_list[i]] = per_model_data_dict.get(other_chem_list[i])\n",
    "      \n",
    "        df_perc.to_excel(writer, sheet_name=f\"{cec_list[0]}\")\n",
    "        writer.save()\n",
    "            \n",
    " \n",
    "        chem_model_map = self.get_chem_model_map(training_pred_score_path, chemical)\n",
    "        model_names = chem_model_map.get(chemical)\n",
    "\n",
    "     \n",
    "            \n",
    "\n",
    "        model_names = chem_model_map.get(chemical)\n",
    "\n",
    "          \n",
    "        df_= pd.read_excel(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_%_False_y_pred_list_df.xlsx'),index_col=0, engine='openpyxl')\n",
    "        \n",
    "        df_ = df_.dropna()\n",
    "        df_.to_excel(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_%_False_y_pred_list_df.xlsx'))\n",
    "        df_.to_csv(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_%_False_y_pred_list_df.csv'))\n",
    "        for model_name in model_names:\n",
    "            df.to_pickle(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_%_{model_name}_regression_False_score_trained.pkl'))\n",
    "        return\n",
    "    def _wetchem_phosphorus_df(self , df):\n",
    "        df_phosphorus = pd.DataFrame(columns=['no_samples','recall_score','precision_score','f1_score','accuracy_score'], index=df.columns)\n",
    "        return df_phosphorus\n",
    "    \n",
    "    def _preds_vs_wet_statistics(self, training_pred_score_path, chemical, codes=None ):\n",
    "        print(\"....Predictions vs Wetchem statistics..........\")\n",
    "        added_chemicals = ['calcium_%', 'potassium_%','magnesium_%']\n",
    "#         if chemical =='calcium':\n",
    "#             chemical = 'calcium_%'\n",
    "#         elif chemical =='potassium':\n",
    "#             chemical = 'potassium_%'\n",
    "#         else:\n",
    "#             pass\n",
    "        method = 'regression'\n",
    "        method2 = self.method2\n",
    "        \n",
    "        print(\"Method 1\",method)\n",
    "        print(\"Method 2\",method2)\n",
    "        _wetchem_statistics = self._wetchem_statistics\n",
    "        _wetchem_phosphorus_df = self._wetchem_phosphorus_df\n",
    "        \n",
    "        if codes != None :\n",
    "            df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "            df = df.reindex(codes)\n",
    "        else:\n",
    "#             if chemical in added_chemicals:\n",
    "#                 df = pd.read_excel(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.xlsx'),index_col=0)\n",
    "#             else:\n",
    "            df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "        comb_df_list = []\n",
    "        comb_df_list2 = []\n",
    "        \n",
    "        chem_model_map = self.get_chem_model_map(training_pred_score_path, chemical)\n",
    "        print(\"Chemical models map\",chem_model_map)\n",
    "        for models_ in chem_model_map.get(chemical):\n",
    "            model_first_name =  models_\n",
    "\n",
    "#                 df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "            print(\n",
    "                \"CV Model Evaluation for chemical={}, mlmodel={}\".format(\n",
    "                    chemical, model_first_name\n",
    "                )\n",
    "            )\n",
    "            df = df.dropna()\n",
    "\n",
    "            df_Q0_Q025 = df[df.y_true_val.between(*df.y_true_val.quantile([0,0.25 ]).tolist())]\n",
    "            df_Q025_Q050 = df[df.y_true_val.between(*df.y_true_val.quantile([0.25,0.5 ]).tolist())]\n",
    "            df_Q050_Q075 = df[df.y_true_val.between(*df.y_true_val.quantile([0.5,0.75 ]).tolist())]\n",
    "            df_Q075_Q1 = df[df.y_true_val.between(*df.y_true_val.quantile([0.75,1 ]).tolist())]\n",
    "            df_Q0_Q050 = df[df.y_true_val.between(*df.y_true_val.quantile([0,0.5 ]).tolist())]\n",
    "            df_Q050_Q075 = df[df.y_true_val.between(*df.y_true_val.quantile([0.5,0.75 ]).tolist())]\n",
    "            xq1=df_Q0_Q025['y_true_val']\n",
    "            yq1=df_Q0_Q025[f'{model_first_name}_regression']\n",
    "            xq2=df_Q025_Q050['y_true_val']\n",
    "            yq2=df_Q025_Q050[f'{model_first_name}_regression']\n",
    "            xq3=df_Q050_Q075['y_true_val']\n",
    "            yq3=df_Q050_Q075[f'{model_first_name}_regression']\n",
    "            xq4=df_Q075_Q1['y_true_val']\n",
    "            yq4=df_Q075_Q1[f'{model_first_name}_regression']\n",
    "\n",
    "            x=df['y_true_val']\n",
    "            y=df[f'{model_first_name}_regression']\n",
    "            slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "            df_regression = _wetchem_statistics(df[['y_true_val',f'{model_first_name}_regression']])\n",
    "            df_regression['Model'] = np.nan\n",
    "            rmse = mean_squared_error(x, y) ** 0.5\n",
    "            r2_squared = r2_score(x, y)\n",
    "            rsc = x.std()/rmse\n",
    "            df_regression.at['y_true_val', 'slope'] = self._round_sig(slope)\n",
    "            df_regression.at['y_true_val', 'intercept'] = self._round_sig(intercept)\n",
    "            df_regression.at['y_true_val', 'RMSE'] = self._round_sig(rmse)\n",
    "            df_regression.at['y_true_val', 'RSC'] = self._round_sig(rsc)\n",
    "            df_regression.at['y_true_val', 'R2'] = self._round_sig(r2_squared)\n",
    "            df_regression.at['y_true_val', 'RMSECVQ1'] = self._round_sig( mean_squared_error(xq1, yq1) ** 0.5)\n",
    "            df_regression.at['y_true_val', 'RMSECVQ2'] = self._round_sig( mean_squared_error(xq2, yq2) ** 0.5)\n",
    "            df_regression.at['y_true_val', 'RMSECVQ3'] = self._round_sig( mean_squared_error(xq3, yq3) ** 0.5)\n",
    "            df_regression.at['y_true_val', 'RMSECVQ4'] = self._round_sig( mean_squared_error(xq4, yq4) ** 0.5)\n",
    "            df_regression['Model'].fillna(f'{model_first_name}_regression', inplace=True)\n",
    "            df_regression.drop([f'{model_first_name}_regression'], inplace=True)\n",
    "            df_regression.rename(index = {'y_true_val':chemical}, inplace=True)\n",
    "\n",
    "            comb_df_list.append(df_regression)\n",
    "\n",
    "        regressor_chemicals = len(comb_df_list)\n",
    "        if regressor_chemicals > 0:\n",
    "            comb_df= pd.concat(comb_df_list)\n",
    "            comb_df.drop_duplicates(inplace=True)\n",
    "        else:\n",
    "            comb_df= pd.DataFrame()\n",
    "\n",
    "\n",
    "        \n",
    "        class_chemicals = len(comb_df_list2)\n",
    "        if class_chemicals > 0:\n",
    "            comb_df_class= pd.concat(comb_df_list2)\n",
    "            comb_df_class.drop_duplicates(inplace=True)\n",
    "        else:\n",
    "            comb_df_class= pd.DataFrame()\n",
    "        \n",
    "        \n",
    "        \n",
    "        return comb_df , comb_df_class\n",
    "    def chem_to_percentage_conversion(self, training_pred_score_path,chemicals_conv, codes=None):\n",
    "#         \n",
    "        chems = ['potassium','calcium','magnesium']\n",
    "    \n",
    "        for chemical in chemicals_conv:\n",
    "            if chemical not in chems:\n",
    "                pass\n",
    "            else:\n",
    "            \n",
    "        #             try:\n",
    "                df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "    #             print(df)\n",
    "    #             \n",
    "\n",
    "                if codes != None:\n",
    "\n",
    "                    df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "\n",
    "                    cec_df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/','cec_False_y_pred_list_df.csv'),index_col=0)\n",
    "                    df = df.reindex(codes)\n",
    "\n",
    "                    cec_df = cec_df.reindex(codes)\n",
    "                else:\n",
    "                    df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "\n",
    "                    cec_df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/','cec_False_y_pred_list_df.csv'),index_col=0)\n",
    "\n",
    "                df_perc = pd.DataFrame(np.zeros((df.shape[0], df.shape[1])), index=df.index, columns=df.columns)\n",
    "                if chemical == 'calcium':\n",
    "                    num_divider = 200\n",
    "                    self.ppm_to_percentage(cec_df, training_pred_score_path , df_perc, df, num_divider,chemical)\n",
    "                elif chemical == 'magnesium':\n",
    "                    num_divider = 120\n",
    "                    self.ppm_to_percentage(cec_df, training_pred_score_path , df_perc, df, num_divider,chemical)\n",
    "                else:\n",
    "                    num_divider = 390\n",
    "                    self.ppm_to_percentage(cec_df, training_pred_score_path , df_perc, df, num_divider,chemical)\n",
    "#             except:\n",
    "#                 pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "98231926",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotModelStats:\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a class where various plots are produced to display models performance\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    def __init__(self , **kwargs: dict):\n",
    "\n",
    "        self.__dict__.update(kwargs)\n",
    "        allowed_keys = ['outpath', 'method','chemicals_with_percentage']\n",
    "\n",
    "        self.__dict__.update((k,v) for k, v in kwargs.items() if k in allowed_keys)\n",
    "\n",
    "        if not hasattr(self, 'outpath'):\n",
    "            self.outhpath = os.getcwd()\n",
    "        \n",
    "        if not hasattr(self, 'method'):\n",
    "            self.method = \"regression\"\n",
    "        if not hasattr(self, 'chemicals_with_percentage'):\n",
    "            self.method = \"chemicals_with_percentage\"\n",
    "\n",
    "\n",
    "    def _plot_confusion_matrix_plotly(self, cm, training_pred_score_path,chemical,model_first_name,area,normalize=False,plot=False, codes=None): \n",
    "        cm_path = training_pred_score_path\n",
    "        \n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            cm = cm.round(4)\n",
    "            normalized = 'original_normalized'\n",
    "        else:\n",
    "            normalized = 'non_normalized'\n",
    "        target_names =['very_low','low','optimum','high']\n",
    "        fig = ff.create_annotated_heatmap(cm.transpose(), x=target_names, y=target_names, colorscale='blues', showscale=True, reversescale=False)\n",
    "        fig['layout']['xaxis'].update(side='bottom', title='True')\n",
    "        fig['layout']['yaxis'].update(side='left', title='Predicted')\n",
    "        fig.update_layout(title=f'{area} {model_first_name} {chemical} confusion matrix')\n",
    "        if plot == True:\n",
    "\n",
    "            fig.show()\n",
    "        else:\n",
    "            \n",
    "            cm_plot_path_subset = os.path.join(cm_path, 'saved_models', 'confusion_matrix_subset','{}_{}_{}_cm.png'.format(chemical, model_first_name, normalized))\n",
    "            cm_plot_path = os.path.join(cm_path, 'saved_models', 'confusion_matrix','{}_{}_{}_cm.png'.format(chemical, model_first_name, normalized))\n",
    "            if codes != None:\n",
    "                \n",
    "                os.makedirs(os.path.join(cm_path, 'saved_models', 'confusion_matrix_subset'),exist_ok=True)\n",
    "                fig.write_image(cm_plot_path_subset)\n",
    "            else:\n",
    "                os.makedirs(os.path.join(cm_path, 'saved_models', 'confusion_matrix'),exist_ok=True)\n",
    "                fig.write_image(cm_plot_path)\n",
    "\n",
    "    def _create_confusion_matrices(self, training_pred_score_path, region,chem_correction, chemicals_conv, codes=None):\n",
    "        area = region\n",
    "        method = 'classification'\n",
    "\n",
    "\n",
    "        path_to_saved_models =  os.path.join(training_pred_score_path, 'saved_models')\n",
    "#         \n",
    "        guides = {\n",
    "        'boron' : [-1e6, 0.5, 0.8, 1, 1e6],\n",
    "        'calcium_%' : [-1e6, 40, 60, 65, 1e6],\n",
    "        'cec' : [-1e6, 8, 15, 20, 1e6],\n",
    "        'copper' : [-1e6, 1, 1.5, 8, 1e6],\n",
    "        'iron' : [-1e6, 20, 30, 50, 1e6],\n",
    "        'magnesium_%' : [-1e6, 8, 10, 15, 1e6], \n",
    "        'manganese' : [-1e6, 10, 20, 100, 1e6],\n",
    "        'potassium_%' : [-1e6, 1.5, 3, 5, 1e6], \n",
    "        'ph' : [-1e6, 5.5, 5.8, 6.4, 1e6],\n",
    "        'organic_carbon' : [-1e6, 1, 2, 4, 1e6],\n",
    "        'sulphur' : [-1e6, 5, 10, 20, 1e6],\n",
    "        'total_nitrogen' : [-1e6, 0.1, 0.2, 0.25, 1e6],\n",
    "        'zinc' : [-1e6, 1, 2, 4, 1e6],\n",
    "        'phosphorus' : [-1e6, 10, 30, 50, 1e6]\n",
    "    }\n",
    "\n",
    "        chem_with_plots = []\n",
    "        for chemical in chemicals_conv:\n",
    "            \n",
    "            \n",
    "            if method == 'classification':\n",
    "                chem_model_map = EvaluationTool().get_chem_model_map(training_pred_score_path, chemical)\n",
    "                print(chem_model_map)\n",
    "                for models_ in chem_model_map.get(chemical):\n",
    "                    model_first_name = models_\n",
    "                    if chemical in guides.keys(): \n",
    "                        \n",
    "                        chem_with_plots.append(chemical)\n",
    "                        df = pd.read_csv(os.path.join(training_pred_score_path, 'saved_models/{}_False_y_pred_list_df.csv'.format(chemical)), index_col=0)\n",
    "                        y_val = df['y_true_val'].values\n",
    "                        y_preds = df[f'{model_first_name}_regression'].values\n",
    "                        preds_vs_wet_temp = pd.DataFrame([y_val.reshape(-1,), y_preds.reshape(-1,)], index=['wet','preds']).T\n",
    "                    #     break\n",
    "                        preds_vs_wet_temp[f'{chemical}_labels'] = pd.cut(preds_vs_wet_temp['wet'].dropna(), bins = guides[f'{chemical}'], labels = [\"very_low\", \"low\", \"optimum\", \"high\"])\n",
    "                        preds_vs_wet_temp[\"label_code\"] = preds_vs_wet_temp[f'{chemical}_labels'].cat.codes\n",
    "\n",
    "                        preds_vs_wet_temp[f'{chemical}_labels_preds'] = pd.cut(preds_vs_wet_temp['preds'].dropna(), bins = guides[f'{chemical}'], labels = [ \"very_low\", \"low\", \"optimum\", \"high\"])\n",
    "                        \n",
    "                        if chem_correction==True and chemical =='phosphorus':\n",
    "                            preds_vs_wet_temp = self.p_correction_v3(preds_vs_wet_temp, chemical)\n",
    "                            \n",
    "\n",
    "                            preds_vs_wet_temp[\"label_preds_code\"] = preds_vs_wet_temp[f'{chemical}_labels_preds'].cat.codes\n",
    "#                           \n",
    "                        else:\n",
    "#                             print(f'{chemical}.....TRUEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE')\n",
    "                \n",
    "                            preds_vs_wet_temp[\"label_preds_code\"] = preds_vs_wet_temp[f'{chemical}_labels_preds'].cat.codes\n",
    "                        \n",
    "                                \n",
    "                       \n",
    "                        \n",
    "                        target_names =['very_low','low','optimum','high']\n",
    "                        if codes != None :                          \n",
    "                            preds_vs_wet_temp.to_csv(os.path.join(training_pred_score_path,f'{chemical}_{model_first_name}_classes_subset.csv'))\n",
    "                        else:\n",
    "                            preds_vs_wet_temp.to_csv(os.path.join(training_pred_score_path,f'{chemical}_{model_first_name}_classes.csv'))\n",
    "                        # cm = confusion_matrix(preds_vs_wet_temp[f'{chemical}_labels'], preds_vs_wet_temp[f'{chemical}_labels_preds'], labels=target_names)\n",
    "\n",
    "                        cm = confusion_matrix(preds_vs_wet_temp['label_code'],preds_vs_wet_temp['label_preds_code'], labels=[0 , 1 , 2 , 3])\n",
    "                        \n",
    "                        if codes != None:\n",
    "                            self._plot_confusion_matrix_plotly(cm,training_pred_score_path,chemical,model_first_name,area,normalize=False,plot=False, codes=codes)\n",
    "                            self._plot_confusion_matrix_plotly(cm,training_pred_score_path,chemical,model_first_name, area,normalize=True,plot=False, codes=codes)\n",
    "                            self.combine_cm_matrices(training_pred_score_path, codes=codes)\n",
    "                        else:\n",
    "                            self._plot_confusion_matrix_plotly(cm,training_pred_score_path,chemical,model_first_name,area,normalize=False,plot=False, codes=None)\n",
    "                            self._plot_confusion_matrix_plotly(cm,training_pred_score_path,chemical,model_first_name, area,normalize=True,plot=False, codes=None)\n",
    "                            self.combine_cm_matrices(training_pred_score_path, codes=None)\n",
    "                        \n",
    "        #to handle duplicate chemicals in list\n",
    "        chem_with_list = OrderedDict.fromkeys(chem_with_plots)\n",
    "        for chemical in chem_with_list: \n",
    "            if method == 'regression':\n",
    "#                 chemical = EvaluationTool().reversed_chemical_name(chemical)\n",
    "                if codes != None:\n",
    "                    \n",
    "                    self.combine_confusion_matrices(training_pred_score_path, chemical, codes=codes)\n",
    "                else:\n",
    "                    self.combine_confusion_matrices(training_pred_score_path, chemical, codes=None)\n",
    "        return  \n",
    "    def combine_cm_matrices(self,training_pred_score_path, codes=None):\n",
    "        # TO DO : change from hardcoded no of images and dimensions to dynamic\n",
    "        saved_models_path = training_pred_score_path\n",
    "        if codes != None:\n",
    "            delimiter_subset = '/saved_models/confusion_matrix_subset/*original_normalized_cm.png'\n",
    "        else:\n",
    "            delimiter = '/saved_models/confusion_matrix/*original_normalized_cm.png'\n",
    "        img = np.zeros([1920,2560,3],dtype=np.uint8)\n",
    "        img.fill(255)\n",
    "        if codes != None:\n",
    "            os.makedirs( os.path.join(saved_models_path, 'saved_models', 'confusion_matrix_subset'),exist_ok=True)\n",
    "            cm_blank_path = os.path.join(saved_models_path, 'saved_models', 'confusion_matrix_subset', 'norm_cm_blank.png')\n",
    "            cm_comb_path = os.path.join(saved_models_path, 'saved_models', 'confusion_matrix_subset', 'comb_norm_cm.png')\n",
    "            imsave(cm_blank_path, img)\n",
    "        else:   \n",
    "            os.makedirs( os.path.join(saved_models_path, 'saved_models', 'confusion_matrix'),exist_ok=True)\n",
    "            cm_blank_path = os.path.join(saved_models_path, 'saved_models', 'confusion_matrix', 'norm_cm_blank.png')\n",
    "            cm_comb_path = os.path.join(saved_models_path, 'saved_models', 'confusion_matrix', 'comb_norm_cm.png')\n",
    "            imsave(cm_blank_path, img)\n",
    "        if codes != None:\n",
    "            all_files = sorted(glob.glob(saved_models_path + delimiter_subset))\n",
    "        else:\n",
    "            all_files = sorted(glob.glob(saved_models_path + delimiter))\n",
    "        blank_image = Image.open(cm_blank_path)\n",
    "        height = 0\n",
    "        width = 0\n",
    "        for file in all_files:\n",
    "            cm = Image.open(file)\n",
    "            blank_image.paste(cm, (width, height))\n",
    "            if width < 1920:\n",
    "                width += 640\n",
    "            else:\n",
    "                width = 0\n",
    "                height += 480\n",
    "        blank_image.save(cm_comb_path)\n",
    "        if codes != None:\n",
    "            delimiter = '/saved_models/confusion_matrix_subset/*_non_normalized_cm.png'\n",
    "        else:\n",
    "            delimiter = '/saved_models/confusion_matrix/*_non_normalized_cm.png'\n",
    "        img = np.zeros([1920,2560,3],dtype=np.uint8)\n",
    "        img.fill(255)\n",
    "        if codes != None:\n",
    "            cm_blank_path = os.path.join(saved_models_path,'saved_models', 'confusion_matrix_subset', 'unnorm_cm_blank.png')\n",
    "            cm_comb_path = os.path.join(saved_models_path,'saved_models', 'confusion_matrix_subset', 'comb_unnorm_cm.png')\n",
    "        else:\n",
    "            cm_blank_path = os.path.join(saved_models_path,'saved_models', 'confusion_matrix', 'unnorm_cm_blank.png')\n",
    "            cm_comb_path = os.path.join(saved_models_path,'saved_models', 'confusion_matrix', 'comb_unnorm_cm.png')\n",
    "        imsave(cm_blank_path, img)\n",
    "        if codes != None:\n",
    "            all_files = sorted(glob.glob(saved_models_path + delimiter_subset))\n",
    "        else:\n",
    "            all_files = sorted(glob.glob(saved_models_path + delimiter))\n",
    "        blank_image = Image.open(cm_blank_path)\n",
    "        height = 0\n",
    "        width = 0\n",
    "        for file in all_files:\n",
    "            cm = Image.open(file)\n",
    "            blank_image.paste(cm, (width, height))\n",
    "            if width < 1920:\n",
    "                width += 640\n",
    "            else:\n",
    "                width = 0\n",
    "                height += 480\n",
    "        blank_image.save(cm_comb_path)\n",
    "        return cm_comb_path\n",
    "\n",
    "\n",
    "    def _PlotScatter(self, training_pred_score_path,chemicals_conv, plot=True, codes=None):\n",
    "        \n",
    "        method = \"regression\"\n",
    "\n",
    "\n",
    "        path_to_saved_models =  os.path.join(training_pred_score_path, 'saved_models')\n",
    "        os.makedirs(os.path.join(path_to_saved_models, 'scatter_plots'), exist_ok =True)\n",
    "\n",
    "        chemicals_conv = list(dict.fromkeys(chemicals_conv))\n",
    "\n",
    "        for chemical in chemicals_conv:\n",
    "            \n",
    "            print(chemical)\n",
    "            if method == 'regression':\n",
    "                print('yes')\n",
    "                chem_model_map = EvaluationTool().get_chem_model_map(training_pred_score_path, chemical)\n",
    "                print( chem_model_map)\n",
    "                for models_ in chem_model_map.get(chemical):\n",
    "                    model_first_name = models_\n",
    "                    print( model_first_name)\n",
    "\n",
    "                    \n",
    "                    if codes !=None:\n",
    "                        if chemical != 'calcium_%' or chemical != 'potassium_%' or chemical != 'magnesium_%':\n",
    "                            df = pd.read_csv(os.path.join(training_pred_score_path, 'saved_models/{}_False_y_pred_list_df.csv'.format(chemical)), index_col=0)\n",
    "                        else:\n",
    "                            df = pd.read_excel(os.path.join(training_pred_score_path, 'saved_models/{}_False_y_pred_list_df.xlsx'.format(chemical)), index_col=0, engine='openpyxl')\n",
    "                        df.index = df.index.str.strip()\n",
    "                        df = df.reindex(codes)\n",
    "                    else:\n",
    "                        if chemical != 'calcium_%' or chemical != 'potassium_%' or chemical != 'magnesium_%':\n",
    "                            df = pd.read_csv(os.path.join(training_pred_score_path, 'saved_models/{}_False_y_pred_list_df.csv'.format(chemical)), index_col=0)\n",
    "                        else:\n",
    "                            df = pd.read_excel(os.path.join(training_pred_score_path, 'saved_models/{}_False_y_pred_list_df.xlsx'.format(chemical)), index_col=0, engine='openpyxl')\n",
    "                        df.index = df.index.str.strip()\n",
    "                        print(df.head())\n",
    "                        print('yes')\n",
    "                    df = df[[f'{model_first_name}_regression', 'y_true_val']]\n",
    "                    y_max =df[f'{model_first_name}_regression'].max()\n",
    "                    x_max =df['y_true_val'].max()\n",
    "                    y_min =df[f'{model_first_name}_regression'].min()\n",
    "                    x_min =df['y_true_val'].min()\n",
    "                    max_dim = max(x_max, y_max)\n",
    "                    fig = px.scatter(df, x='y_true_val', y=f'{model_first_name}_regression',\n",
    "                                trendline=\"ols\")\n",
    "                    fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[0, x_max + x_max/(x_max/2)],\n",
    "                        y=[0, x_max + x_max/(x_max/2)],\n",
    "                        mode=\"lines\",\n",
    "                        line=go.scatter.Line(color=\"gray\"),\n",
    "                        name='1:1 Line',\n",
    "                        showlegend=True)\n",
    "                )\n",
    "                    fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=[0, 0],\n",
    "                        y=[0, 0],\n",
    "                        mode=\"lines\",\n",
    "                        line=go.scatter.Line(color=\"blue\"),\n",
    "                        name='Linear model line',\n",
    "                        showlegend=True)\n",
    "                )\n",
    "\n",
    "                    if chemical == 'ph':\n",
    "                        fig.update_layout(title=f'{model_first_name} Predictions vs Wetchem Scatter for {chemical}', xaxis = dict(range=(df['y_true_val'].min() -1, max_dim + 1 ),constrain='domain',title = 'wetchem'),yaxis = dict(range=(df['y_true_val'].min() -1, max_dim + 1),constrain='domain',title = 'predictions'))\n",
    "                    elif chemical == 'sand':\n",
    "                        fig.update_layout(title=f'{model_first_name} Predictions vs Wetchem Scatter for {chemical}', xaxis = dict(range=(df['y_true_val'].min() - 10, max_dim + 10 ),constrain='domain',title = 'wetchem'),yaxis = dict(range=(df['y_true_val'].min() -10, max_dim + 10),constrain='domain',title = 'predictions'))\n",
    "                    else:\n",
    "                        if y_min < 0:\n",
    "                            fig.update_layout(title=f'{model_first_name} Predictions vs Wetchem Scatter for {chemical}', xaxis = dict(range=(0, max_dim + df['y_true_val'].median()/0.75 ),constrain='domain',title = 'wetchem'),yaxis = dict(range=(y_min, max_dim + df['y_true_val'].median()/0.75 ),constrain='domain',title = 'predictions'))\n",
    "                        else:\n",
    "                            \n",
    "                            fig.update_layout(title=f'{model_first_name} Predictions vs Wetchem Scatter for {chemical}', xaxis = dict(range=(0, max_dim + df['y_true_val'].median()/0.75 ),constrain='domain',title = 'wetchem'),yaxis = dict(range=(0, max_dim + df['y_true_val'].median()/0.75 ),constrain='domain',title = 'predictions'))\n",
    "                    if plot:\n",
    "\n",
    "                        fig.show()\n",
    "                    else:\n",
    "                        if codes != None :\n",
    "                            \n",
    "                            cm_plot_path = os.path.join(training_pred_score_path, 'saved_models', 'scatter_plots_subset','{}_{}.png'.format(chemical, model_first_name))\n",
    "                            os.makedirs(os.path.join(training_pred_score_path, 'saved_models', 'scatter_plots_subset'),exist_ok=True)\n",
    "                        else:\n",
    "                            cm_plot_path = os.path.join(training_pred_score_path, 'saved_models', 'scatter_plots','{}_{}.png'.format(chemical, model_first_name))\n",
    "                            os.makedirs(os.path.join(training_pred_score_path, 'saved_models', 'scatter_plots'),exist_ok=True)\n",
    "                        fig.write_image(cm_plot_path)\n",
    "                        \n",
    "        for chemical in chemicals_conv:  \n",
    "#             chemical = EvaluationTool().reversed_chemical_name(chemical)\n",
    "            if method == 'regression':\n",
    "                if codes != None:\n",
    "                    \n",
    "                    self.combine_scatter_plots(training_pred_score_path, chemical, codes=codes)\n",
    "                else:\n",
    "                    if len(models_)> 1:\n",
    "                        print(\"REacheed chem + +++++++++++++++++++++++++++++++++ ++ \", chemical)\n",
    "                        self.combine_scatter_plots(training_pred_score_path, chemical, codes=None)\n",
    "                    else:\n",
    "                        pass\n",
    "                \n",
    "            \n",
    "        return\n",
    "    def Image_combiner(self, all_files):\n",
    "        images = [Image.open(x) for x in all_files]\n",
    "        widths, heights = zip(*(i.size for i in images))\n",
    "\n",
    "        total_width = sum(widths)\n",
    "        max_height = max(heights)\n",
    "        new_im = Image.new('RGB', (total_width, max_height))\n",
    "\n",
    "        x_offset = 0\n",
    "        for im in images:\n",
    "            \n",
    "            new_im.paste(im, (x_offset,0))\n",
    "            x_offset += im.size[0]\n",
    "        return new_im\n",
    "    \n",
    "    def combine_scatter_plots(self, training_pred_score_path, chemical, codes=None):\n",
    "        chemical_to_separate = ['calcium','magnesium','potassium','phosphorus']\n",
    "        chem_map = EvaluationTool().get_chem_model_map(training_pred_score_path, chemical)\n",
    "        if codes != None:\n",
    "                \n",
    "            delimiter = f'/saved_models/scatter_plots_subset/{chemical}*'\n",
    "        else:\n",
    "            delimiter = f'/saved_models/scatter_plots/{chemical}*'\n",
    "            \n",
    "        if chemical == 'ph': \n",
    "            \n",
    "            delimiter = f'/saved_models/scatter_plots/{chemical}_*'\n",
    "            all_files = sorted(glob.glob(training_pred_score_path + delimiter))\n",
    "            \n",
    "        \n",
    "        elif chemical in chemical_to_separate:\n",
    "            delimiter = f'/saved_models/scatter_plots/{chemical}_DL*'\n",
    "            all_files = sorted(glob.glob(training_pred_score_path + delimiter))\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            all_files = sorted(glob.glob(training_pred_score_path + delimiter))\n",
    "        \n",
    "        \n",
    "        new_im = self.Image_combiner(all_files)\n",
    "        if codes != None:\n",
    "            \n",
    "            new_im.save(os.path.join(training_pred_score_path ,'saved_models','scatter_plots_subset', f'{chemical} combined_scatter_plot.png'))\n",
    "        else:\n",
    "            new_im.save(os.path.join(training_pred_score_path ,'saved_models','scatter_plots', f'{chemical} combined_scatter_plot.png'))\n",
    "    \n",
    "    def combine_confusion_matrices(self,training_pred_score_path, chemical, codes=None ):\n",
    "        chem_map = EvaluationTool().get_chem_model_map(training_pred_score_path, chemical)\n",
    "        if codes != None:\n",
    "            chem_delimiter = f'/saved_models/confusion_matrix_subset/{chemical}*'\n",
    "        else: \n",
    "            chem_delimiter = f'/saved_models/confusion_matrix/{chemical}*'\n",
    "        all_files_chem = sorted(glob.glob(training_pred_score_path + chem_delimiter))\n",
    "        if chemical =='ph':\n",
    "            number_of_plots = len(chem_map[chemical])\n",
    "            all_files_chem = all_files_chem[:number_of_plots]\n",
    "        else:\n",
    "            pass\n",
    "        non_norm_list = []\n",
    "        norm_list = []\n",
    "        for path in all_files_chem:\n",
    "            if path.endswith('_non_normalized_cm.png'):\n",
    "                non_norm_list.append(path)\n",
    "            else:\n",
    "                norm_list.append(path)\n",
    "        \n",
    "        new_im_norm = self.Image_combiner(norm_list)\n",
    "        new_im_un_norm = self.Image_combiner(non_norm_list)\n",
    "        if codes != None:\n",
    "            \n",
    "            new_im_norm.save(os.path.join(training_pred_score_path ,'saved_models','confusion_matrix_subset', f'{chemical} combined_normalized_confusion.png'))\n",
    "            new_im_un_norm.save(os.path.join(training_pred_score_path ,'saved_models','confusion_matrix_subset', f'{chemical} combined_unormalized_confusion.png'))\n",
    "        else:\n",
    "            new_im_norm.save(os.path.join(training_pred_score_path ,'saved_models','confusion_matrix', f'{chemical} combined_normalized_confusion.png'))\n",
    "            new_im_un_norm.save(os.path.join(training_pred_score_path ,'saved_models','confusion_matrix', f'{chemical} combined_unormalized_confusion.png'))\n",
    "            \n",
    "\n",
    "\n",
    "    def p_correction_v3(self,preds_vs_wet_temp, chemical):\n",
    "        guides = {\n",
    "                     'phosphorus' : [-1e6, 30, 50, 80, 1e6],}\n",
    "        \n",
    "        preds_vs_wet_temp[f'{chemical}_labels_preds'] = pd.cut(preds_vs_wet_temp['preds'].dropna(), bins = guides[f'{chemical}'], labels = [ \"very_low\", \"low\", \"optimum\", \"high\"])\n",
    "        preds_vs_wet_temp[\"label_preds_code\"] = preds_vs_wet_temp[f'{chemical}_labels_preds'].cat.codes\n",
    "\n",
    "\n",
    "        return preds_vs_wet_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4d4bdf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saved_eval_params(training_pred_score_path,project_name, lines,lines_dict):\n",
    "    import logging\n",
    "    today = date.today()\n",
    "\n",
    "    d1 = today.strftime(\"%Y/%m/%d\")\n",
    "    d1 = d1.replace('/','_')\n",
    "    dl_new = f'{d1}_{project_name}_v2.0_v2.2_v5'\n",
    "    LOG_FILENAME = os.path.join(training_pred_score_path ,f'reproducing_evaluation.log')\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "    logging.basicConfig(filename=LOG_FILENAME,level=logging.DEBUG)\n",
    "    for num, line in enumerate(lines):\n",
    "\n",
    "        logging.info(f'{lines_dict[num]}: {line}')\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "652a146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_uneccessay_files(training_pred_score_path):\n",
    "\n",
    "    path_list = []\n",
    "    for path, subdirs, files in os.walk(training_pred_score_path):\n",
    "        for name in files:\n",
    "            print(os.path.join(path, name))\n",
    "            path_ = os.path.join(path, name)\n",
    "            if 'norm_cm_blank' in path_:\n",
    "\n",
    "                path_list.append(path_)\n",
    "\n",
    "            elif 'classes_Evaluation' in path_:\n",
    "\n",
    "\n",
    "                path_list.append(path_)\n",
    "            \n",
    "    return [os.remove(x) for x in path_list]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "343f2e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(training_pred_score_path):\n",
    "\n",
    "    path_list = []\n",
    "    for path, subdirs, files in os.walk(training_pred_score_path):\n",
    "        for name in files:\n",
    "            print(os.path.join(path, name))\n",
    "            path_ = os.path.join(path, name)\n",
    "            if '.png' in path_:\n",
    "\n",
    "                path_list.append(path_)\n",
    "\n",
    "    return [os.remove(x) for x in path_list]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7b753ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Models_Summary:\n",
    "    \n",
    "    \"\"\"\n",
    "    This is a class where all evaluation reports plots are produced for Models Trained\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    def __init__(self , **kwargs: dict):\n",
    "\n",
    "        self.__dict__.update(kwargs)\n",
    "        allowed_keys = ['outpath']\n",
    "\n",
    "        self.__dict__.update((k,v) for k, v in kwargs.items() if k in allowed_keys)\n",
    "\n",
    "        if not hasattr(self, 'outpath'):\n",
    "            \n",
    "            self.outhpath = os.getcwd()\n",
    "            \n",
    "    \n",
    "\n",
    "    def __init__(self , **kwargs: dict):\n",
    "\n",
    "        self.__dict__.update(kwargs)\n",
    "        allowed_keys = ['outpath','method','method2']\n",
    "\n",
    "        self.__dict__.update((k,v) for k, v in kwargs.items() if k in allowed_keys)\n",
    "\n",
    "        if not hasattr(self, 'outpath'):\n",
    "            \n",
    "            self.outhpath = os.getcwd()\n",
    "        \n",
    "        if not hasattr(self, 'method'):\n",
    "            \n",
    "            self.method = 'regression'\n",
    "        if not hasattr(self, 'method2'):\n",
    "            \n",
    "            self.method2 = 'classification'\n",
    "            \n",
    "            \n",
    "    def Models_Summary(self, training_pred_score_path, project_name, working_metrics,corrected_chems=None,chem_correction=None,training_pred_score_paths=None,wet_chem_path=None ,predict=False, codes=None):\n",
    "\n",
    "\n",
    "        added_chemicals = ['calcium_%', 'potassium_%','magnesium_%']\n",
    "        \n",
    "\n",
    "        chemicals_conv = []\n",
    "        \n",
    "        path_to_saved_models =  os.path.join(training_pred_score_path, 'saved_models')\n",
    "        path_to_saved_models = Path(path_to_saved_models)\n",
    "#         all_models_chems = [x for x in path_to_saved_models.glob('**/*False_y_pred_list_df.csv')]\n",
    "#         for models_chem in all_models_chems:\n",
    "#                     chem_ = models_chem.stem.split('_False')[0]\n",
    "#                     chemicals_conv.append(chem_)\n",
    "        all_models_chems = os.listdir(training_pred_score_path)\n",
    "        print(all_models_chems)\n",
    "                \n",
    "        \n",
    "\n",
    "        if wet_chem_path != None:\n",
    "            wet_chem = pd.read_csv(wet_chem_path, index_col=0)\n",
    "        method = 'regression'\n",
    "        method2 = 'classification'\n",
    "        region = project_name\n",
    "\n",
    "        if predict == True:\n",
    "            all_preds = glob.glob(training_pred_score_path + f'/*.csv')\n",
    "            df_chems = pd.read_csv(all_preds[0],index_col=0)\n",
    "            chems = pd.read_csv(all_preds[0],index_col=0).columns.tolist()\n",
    "            os.makedirs(os.path.join(training_pred_score_path , 'saved_models'),exist_ok=True)\n",
    "            shutil.copy2(all_preds[0], os.path.join(training_pred_score_path , 'saved_models'))\n",
    "            predictions_path = glob.glob(os.path.join(training_pred_score_path , 'saved_models') + f'/*.csv')\n",
    "            \n",
    "            for chem in chems:\n",
    "                \n",
    "                best_model = best_models.at[chem, 'model']\n",
    "                df_ = df_chems[chem].to_frame()\n",
    "                df_wet = wet_chem[chem].to_frame()\n",
    "                df_ = df_.rename(columns ={chem : f'{best_model}_regression'})\n",
    "                df_wet = df_wet.rename(columns ={chem : 'y_true_val'})\n",
    "                comb_df = pd.concat([df_,df_wet],axis=1)\n",
    "                comb_df.to_csv(os.path.join(training_pred_score_path , 'saved_models',f'{chem}_False_y_pred_list_df.csv'))\n",
    "                comb_df.to_pickle(os.path.join(training_pred_score_path , 'saved_models',f'{chem}_{best_model}_regression_False_score_trained.pkl'))\n",
    "                \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "        if codes != None:\n",
    "#             EvaluationTool().chem_to_percentage_conversion(training_pred_score_path, codes=codes)\n",
    "            PlotModelStats()._PlotScatter(training_pred_score_path,chemicals_conv, plot=False, codes=codes)\n",
    "            try:\n",
    "                PlotModelStats()._create_confusion_matrices(training_pred_score_path, region,chemicals_conv, codes=codes)\n",
    "            except:\n",
    "                pass\n",
    "            path_to_save = os.path.join(training_pred_score_path, 'saved_models', 'Predictions_subset')\n",
    "            os.makedirs(path_to_save, exist_ok=True)\n",
    "        else:\n",
    "            if chem_correction:\n",
    "#                 EvaluationTool().chem_to_percentage_conversion(training_pred_score_path,chem_correction)\n",
    "#                 path_to_remove = [x for x in os.listdir(os.path.join(training_pred_score_path, 'saved_models') ) if 'cec' in x]\n",
    "#                 try:\n",
    "#                     for ptr in path_to_remove:\n",
    "#                          os.remove(os.path.join(training_pred_score_path,'saved_models/',ptr))\n",
    "#                     chemicals_conv.remove('cec')\n",
    "#                 except:\n",
    "#                     pass\n",
    "                    \n",
    "                PlotModelStats()._PlotScatter(training_pred_score_path,chemicals_conv, plot=False)\n",
    "                PlotModelStats()._create_confusion_matrices(training_pred_score_path, region,chem_correction,chemicals_conv =chemicals_conv, codes=codes)\n",
    "             \n",
    "            else:\n",
    "                \n",
    "#                 pass\n",
    "                EvaluationTool().chem_to_percentage_conversion(training_pred_score_path,chemicals_conv)\n",
    "                PlotModelStats()._PlotScatter(training_pred_score_path,chemicals_conv, plot=False)\n",
    "                PlotModelStats()._create_confusion_matrices(training_pred_score_path, region,chem_correction,chemicals_conv =chemicals_conv, codes=codes)\n",
    "\n",
    "            path_to_save = os.path.join(training_pred_score_path, 'saved_models', 'Predictions')\n",
    "            os.makedirs(path_to_save, exist_ok=True)\n",
    "        \n",
    "        \n",
    "        p_df = pd.DataFrame()\n",
    "        other_chems = pd.DataFrame()\n",
    "        add_chems = ['calcium_%','magnesium_%','potassium_%']\n",
    "        if corrected_chems:\n",
    "            chemicals_conv = ['zinc','phosphorus','potassium']\n",
    "        for chemical in chemicals_conv:\n",
    "            if chemical in add_chems:\n",
    "                print(\"Chemicals was in add_chems\")\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            if codes != None:\n",
    "                print()\n",
    "                df = pd.read_csv(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "                df = df.reindex(codes)\n",
    "                df.to_csv(os.path.join(training_pred_score_path, 'saved_models', 'Predictions_subset', f'predictions_{chemical}.csv'))\n",
    "                \n",
    "            else:\n",
    "                if chemical in added_chemicals:\n",
    "                    \n",
    "                    df = pd.read_excel(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_False_y_pred_list_df.xlsx'),index_col=0, engine='openpyxl')\n",
    "                    df.to_csv(os.path.join(training_pred_score_path, 'saved_models', 'Predictions', f'predictions_{chemical}.csv'))\n",
    "                else:\n",
    "                    df = pd.read_csv(os.path.join(training_pred_score_path, 'saved_models', f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "                    df.to_csv(os.path.join(training_pred_score_path, 'saved_models', 'Predictions', f'predictions_{chemical}.csv'))\n",
    "                \n",
    "#             if method == \"regression\":\n",
    "            if codes != None:\n",
    "                df1, df2 = EvaluationTool()._preds_vs_wet_statistics(training_pred_score_path, chemical, codes=codes )\n",
    "\n",
    "                other_chems = pd.concat([other_chems, df1])\n",
    "            else:\n",
    "\n",
    "                df1, df2 = EvaluationTool()._preds_vs_wet_statistics(training_pred_score_path, chemical, codes=None )\n",
    "                other_chems = pd.concat([other_chems, df1])\n",
    "\n",
    "\n",
    "                \n",
    "        if codes != None :\n",
    "            \n",
    "            \n",
    "            path_to_save = os.path.join(training_pred_score_path,'DLv2.2','saved_models', 'Evaluation_Summary_subset')\n",
    "            os.makedirs(path_to_save, exist_ok=True)\n",
    "            p_df.to_csv(os.path.join(path_to_save, f'classes_Evaluation_{region}_subset.csv'))\n",
    "            other_chems.to_csv(os.path.join(path_to_save, f'Evaluation_{region}_subset.csv'))\n",
    "        else:\n",
    "\n",
    "            path_to_save = os.path.join(training_pred_score_path, 'saved_models', 'Evaluation_Summary')\n",
    "            os.makedirs(path_to_save, exist_ok=True)\n",
    "            \n",
    "            p_df.to_csv(os.path.join(path_to_save, f'classes_Evaluation_{region}.csv'))\n",
    "            other_chems.to_csv(os.path.join(path_to_save, f'Evaluation_{region}.csv'))\n",
    "#             other_chems =  other_chems.drop_duplicates()\n",
    "\n",
    "        if codes != None:\n",
    "            path_to_save = os.path.join(training_pred_score_path, 'saved_models')\n",
    "            df_2 = pd.read_csv(os.path.join(path_to_save,'Evaluation_Summary_subset', f'Evaluation_{region}_subset.csv'), index_col =0)\n",
    "            print(df_2)\n",
    "            df_2 = df_2.reset_index().set_index(['index','Model'])\n",
    "            df_2_copy = df_2.copy()\n",
    "        else:\n",
    "            path_to_save = os.path.join(training_pred_score_path, 'saved_models')\n",
    "            df_2 = pd.read_csv(os.path.join(path_to_save,'Evaluation_Summary', f'Evaluation_{region}.csv'), index_col =0)\n",
    "            print(df_2)\n",
    "            df_2 = df_2.reset_index().set_index(['index','Model'])\n",
    "            df_2_copy = df_2.copy()\n",
    "        list_of_models = []\n",
    "        for chemical in chemicals_conv:\n",
    "            f = EvaluationTool().get_chem_model_map(training_pred_score_path, chemical)\n",
    "            model = f[chemical]\n",
    "            list_of_models.extend(model)\n",
    "            \n",
    "        models = list(dict.fromkeys(list_of_models))\n",
    "        print('+++++++++++MODELSS++++++++++++', models)\n",
    "        \n",
    "#         models = ['DLv2.0','DLv2.2']\n",
    "        \n",
    "        \n",
    "#         models =['StackingBayNuSVR','LightGBM', 'BayesianRidge','ExtGradientBoost']\n",
    "        guides = {\n",
    "        'boron' : [-1e6, 0.5, 0.8, 1, 1e6],\n",
    "        'calcium_%' : [-1e6, 40, 60, 65, 1e6],\n",
    "        'cec' : [-1e6, 8, 15, 20, 1e6],\n",
    "        'copper' : [-1e6, 1, 1.5, 8, 1e6],\n",
    "        'iron' : [-1e6, 20, 30, 50, 1e6],\n",
    "        'magnesium_%' : [-1e6, 8, 10, 15, 1e6], \n",
    "        'manganese' : [-1e6, 10, 20, 100, 1e6],\n",
    "        'potassium_%' : [-1e6, 1.5, 3, 5, 1e6], \n",
    "        'ph' : [-1e6, 5.5, 5.8, 6.4, 1e6],\n",
    "        'organic_carbon' : [-1e6, 1, 2, 4, 1e6],\n",
    "        'sulphur' : [-1e6, 5, 10, 20, 1e6],\n",
    "        'total_nitrogen' : [-1e6, 0.1, 0.2, 0.25, 1e6],\n",
    "        'zinc' : [-1e6, 1, 2, 4, 1e6],\n",
    "        'phosphorus' : [-1e6, 10, 30, 50, 1e6]\n",
    "    }\n",
    "#         chemicals = ['organic_carbon','total_nitrogen',  'sand', 'clay', 'silt']\n",
    "        df_2['PCC0'] =np.nan\n",
    "        df_2['PCC1'] =np.nan\n",
    "        df_2['PCC2'] =np.nan\n",
    "        df_2['PCC3'] =np.nan\n",
    "        chemicals_conv = list(set(chemicals_conv))\n",
    "\n",
    "        for chemical in chemicals_conv:\n",
    "            try:\n",
    "\n",
    "                for model_first_name in models:\n",
    "                    print(chemical)\n",
    "\n",
    "                    df = pd.read_csv(os.path.join(training_pred_score_path,f'{chemical}_{model_first_name}_classes.csv' ), index_col=0)\n",
    "\n",
    "                    df['class_diff'] = abs(df['label_code'] - df['label_preds_code'])\n",
    "\n",
    "                    total_samples = df.shape[0]\n",
    "\n",
    "                    value_counts = df.class_diff.value_counts()\n",
    "\n",
    "                    for class_ in value_counts.index.values:\n",
    "\n",
    "\n",
    "                        df_2.at[(f'{chemical}', f'{model_first_name}_regression'), f'PCC{class_}'] = round((value_counts.loc[class_] / total_samples) * 100, 2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "# #         if chem_correction:\n",
    "# #             chemicals_conv = ['zinc','potassium_%','phosphorus']\n",
    "# #         else:\n",
    "# #             pass\n",
    "# #         print(chemicals_conv)\n",
    "#         df_comb_eval = pd.DataFrame()\n",
    "#         for chemical in chemicals_conv:\n",
    "            \n",
    "            \n",
    "#             for model_first_name in models:\n",
    "#                 try:\n",
    "               \n",
    "                        \n",
    "#                     df = pd.read_csv(os.path.join(training_pred_score_path,f'{chemical}_{model_first_name}_classes.csv' ), index_col=0)\n",
    "\n",
    "#                     df['class_diff'] = abs(df['label_code'] - df['label_preds_code'])\n",
    "\n",
    "#                     total_samples = df.shape[0]\n",
    "\n",
    "#                     value_counts = df.class_diff.value_counts()\n",
    "\n",
    "#                     for class_ in value_counts.index.values:\n",
    "\n",
    "\n",
    "\n",
    "#                         df_temp = df_2.loc[(f'{chemical}', f'{model_first_name}_regression')]\n",
    "#                         pcc_stats = round((value_counts.loc[class_] / total_samples) * 100, 2)\n",
    "\n",
    "#                         df_temp[f'PCC{class_}'] = pcc_stats\n",
    "#                     df_comb_eval = pd.concat([df_comb_eval,df_temp])\n",
    "# #                     df_2.at[(f'{chemical}', f'{model_first_name}_regression'), f'PCC{class_}'] = round((value_counts.loc[class_] / total_samples) * 100, 2)\n",
    "#                 except:\n",
    "#                    pass\n",
    "        df_2.index.name = ('index','Model')\n",
    "        \n",
    "        reset_chems = ['calcium','magnesium','potassium']\n",
    "     \n",
    "        df_2.rename(columns={'PCC0':'Accuracy'}, inplace=True)\n",
    "        \n",
    "        df_2.replace(np.NaN, 0, inplace=True)\n",
    "        \n",
    "#         print(chemical '++++++++++++++++'df_2.columns,'++++++++++++++++')\n",
    "        df_2 = df_2[['Accuracy', 'PCC1', 'PCC2', 'PCC3']]\n",
    "    \n",
    "        df_2_no_dups = df_2.drop_duplicates().reset_index().set_index(['index','Model'])\n",
    "        if codes != None:\n",
    "            \n",
    "#             class_df = pd.read_csv(os.path.join(path_to_save,'Evaluation_Summary_subset', f'classes_Evaluation_{region}_subset.csv'),index_col=0)\n",
    "            eval_df = pd.read_csv(os.path.join(path_to_save,'Evaluation_Summary_subset', f'Evaluation_{region}_subset.csv'),index_col=0)\n",
    "        else:\n",
    "#             class_df = pd.read_csv(os.path.join(path_to_save,'Evaluation_Summary', f'classes_Evaluation_{region}.csv'),index_col=0)\n",
    "            class_df = pd.DataFrame()\n",
    "            eval_df = pd.read_csv(os.path.join(path_to_save,'Evaluation_Summary', f'Evaluation_{region}.csv'),index_col=0)\n",
    "        eval_df = eval_df.reset_index().set_index(['index','Model'])\n",
    "        if class_df.shape[0] > 0:\n",
    "            class_df = class_df.reset_index().set_index(['index','Model'])\n",
    "            class_df.drop('no_samples', axis=1, inplace=True)\n",
    "            df_merged = df_2_no_dups\n",
    "#             .merge(class_df, how='outer', left_index=True, right_index=True)\n",
    "            df_merged2 = eval_df.merge(df_merged, how='outer', left_index=True, right_index=True)\n",
    "        else:\n",
    "            df_merged2 = eval_df.merge(df_2_no_dups, how='outer', left_index=True, right_index=True)\n",
    "        if codes != None:\n",
    "\n",
    "            df_merged2.to_csv(os.path.join(path_to_save,'Evaluation_Summary_subset', f'Evaluation_{region}_subset.csv'))\n",
    "        else:\n",
    "            df_merged2 = df_merged2.drop_duplicates()\n",
    "            for chem in reset_chems:\n",
    "                try:\n",
    "                    df_merged2 = df_merged2.reset_index().set_index('index')\n",
    "\n",
    "                    df_merged2.at[chem, 'Accuracy'] = np.NaN\n",
    "                    df_merged2.at[chem, 'PCC1']= np.NaN\n",
    "                    df_merged2.at[chem, 'PCC2']= np.NaN\n",
    "                    df_merged2.at[chem, 'PCC3']= np.NaN\n",
    "                    df_merged2  = df_merged2.reset_index().set_index(['index','Model'])\n",
    "                except:\n",
    "                    pass\n",
    "            if corrected_chems:\n",
    "                df_merged2['corrected'] = True\n",
    "                df_merged2 = df_merged2.reset_index().set_index('index')\n",
    "                df_merged2 = df_merged2.drop(['calcium','magnesium'])\n",
    "#                 df_merged2 = df_merged2.head(6)\n",
    "                df_merged2.to_csv(os.path.join(path_to_save,'Evaluation_Summary', f'Evaluation_{region}.csv'))\n",
    "                \n",
    "            else:\n",
    "                df_merged2['corrected'] = False\n",
    "                df_merged2.to_csv(os.path.join(path_to_save,'Evaluation_Summary', f'Evaluation_{region}.csv'))\n",
    "            df_guides = pd.DataFrame(guides)\n",
    "            df_guides = df_guides.head(4)\n",
    "            df_guides = df_guides.tail(3)\n",
    "            df_guides.to_csv(os.path.join(path_to_save,'Evaluation_Summary', f'Advice_Guides_{region}.csv'))\n",
    "        best_models_comb_df = pd.DataFrame()\n",
    "        chemicals_conv = list(set(chemicals_conv))\n",
    "        if chem_correction:\n",
    "            chemicals_conv = ['zinc','potassium','phosphorus']\n",
    "        else:\n",
    "            pass\n",
    "        for chemical in chemicals_conv:\n",
    "            \n",
    "#            \n",
    "           \n",
    "            if codes != None:\n",
    "                path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary_subset', f'Evaluation_{region}_subset.csv')\n",
    "                best_model = self.BestModelSelectorPerChem(path_to_evaluation_summary=path_to_evaluation_summary, chemical=chemical,working_metrics=working_metrics)\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary', f'Evaluation_{region}.csv')\n",
    "                if chem_correction:\n",
    "                    pd.read_csv(path_to_evaluation_summary)\n",
    "                print(path_to_evaluation_summary)\n",
    "                if chem_correction:\n",
    "                    best_model = self.BestModelSelectorPerChem(path_to_evaluation_summary=path_to_evaluation_summary, chemical=chemical,working_metrics=working_metrics, chem_correction=True)\n",
    "                else:\n",
    "                    best_model = self.BestModelSelectorPerChem(path_to_evaluation_summary=path_to_evaluation_summary, chemical=chemical,working_metrics=working_metrics, chem_correction=False)\n",
    "            best_model_df = best_model.replace(best_model.iloc[0][0], chemical)\n",
    "            best_models_comb_df = pd.concat([best_models_comb_df, best_model_df])\n",
    "        \n",
    "#             except Exception as e:\n",
    "#                 print(f'{chemical} fails with exception {e}')\n",
    "#                 pass\n",
    "#         print(best_models_comb_df)\n",
    "        best_models_comb_df = best_models_comb_df.rename(columns = {0: 'chemical'}).reset_index().rename(columns = {'index':'Model'}).set_index('chemical')\n",
    "        path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary_subset')\n",
    "        if codes != None: \n",
    "            \n",
    "            best_models_comb_df.to_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'))\n",
    "            best_models = pd.read_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'), index_col = [0,1])\n",
    "            path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary_subset', f'Evaluation_{region}_subset.csv')\n",
    "            evaluation_summary_subset = pd.read_csv(path_to_evaluation_summary, index_col=[0,1])\n",
    "            \n",
    "            comb_df = pd.DataFrame()\n",
    "            for best in range(len(best_models)):\n",
    "                tup_chem_ml = best_models.iloc[best].name\n",
    "                evaluation_summary_subset_2 = evaluation_summary_subset.loc[tup_chem_ml].to_frame().T\n",
    "                comb_df = pd.concat([comb_df,evaluation_summary_subset_2])\n",
    "                path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary_subset')\n",
    "                comb_df.to_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'))\n",
    "        else:\n",
    "            \n",
    "            path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary')\n",
    "            if corrected_chems:\n",
    "                best_models_comb_df['corrected'] = True\n",
    "                best_models_comb_df.to_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'))\n",
    "            else:\n",
    "                best_models_comb_df['corrected'] = False\n",
    "                best_models_comb_df.to_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'))\n",
    "                \n",
    "            \n",
    "\n",
    "                \n",
    "            best_models = pd.read_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'), index_col = [0,1])\n",
    "            path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary', f'Evaluation_{region}.csv')\n",
    "            \n",
    "            evaluation_summary = pd.read_csv(path_to_evaluation_summary, index_col=[0,1])\n",
    "          \n",
    "            comb_df = pd.DataFrame()\n",
    "            for best in range(len(best_models)):\n",
    "                tup_chem_ml = best_models.iloc[best].name\n",
    "               \n",
    "              \n",
    "                evaluation_summary_2 = evaluation_summary.loc[tup_chem_ml].to_frame().T\n",
    "                \n",
    "                comb_df = pd.concat([comb_df,evaluation_summary_2])\n",
    "                path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary')\n",
    "#                 comb_df=comb_df.drop_duplicates()\n",
    "             \n",
    "                comb_df.to_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'))\n",
    "                \n",
    "            folders = ['Evaluation_Summary', 'Predictions','confusion_matrix','scatter_plots']\n",
    "            path_to_save = os.path.join(training_pred_score_path, 'saved_models')\n",
    "            \n",
    "\n",
    "            today = date.today()\n",
    "\n",
    "            d1 = today.strftime(\"%Y/%m/%d\")\n",
    "            d1 = d1.replace('/','_')\n",
    "            \n",
    "            if chem_correction:\n",
    "                pass\n",
    "            else:\n",
    "                \n",
    "                os.makedirs(os.path.join(training_pred_score_path,f'{d1}_{project_name}_v2.0_v2.2_v5'),exist_ok=True)\n",
    "#                 os.makedirs(os.path.join(training_pred_score_path,f'{d1}_{project_name}_v2.0_v2.2_v5'),exist_ok=True)\n",
    "                final_folder = os.path.join(training_pred_score_path,f'{d1}_{project_name}_v2.0_v2.2_v5','pre_correction')\n",
    "                os.makedirs(final_folder,exist_ok=True)\n",
    "                \n",
    "                for folder in folders:\n",
    "\n",
    "    #                 copy_tree(os.path.join(path_to_save, folder), final_folder)\n",
    "    \n",
    "                    current_folder = os.path.join(path_to_save, folder)\n",
    "                    !cp -r {current_folder} {final_folder}\n",
    "\n",
    "        \n",
    "    def conform_headers(self, df):\n",
    "        print('Conforming headers')\n",
    "        old_heads = list(df)\n",
    "        new_heads = []\n",
    "        for feature in old_heads:\n",
    "            feature = str(feature)\n",
    "    # #         print('Replacing feature %s with %s', feature, feature.replace(\" \", \"_\").lower())\n",
    "            new_heads.append(feature.replace(\" \", \"_\"))\n",
    "    #         print('Replacing index %s with %s', df.index.name, df.index.name.replace(\" \", \"_\").lower())\n",
    "        df.index.name = df.index.name.replace(\" \", \"_\").lower()\n",
    "        df.columns = new_heads\n",
    "        return df, new_heads\n",
    "\n",
    "    def BestModelSelectorPerChem(self, path_to_evaluation_summary, chemical, working_metrics,All_metrics= False,chem_correction=False):\n",
    "        eval_summary = pd.read_csv(path_to_evaluation_summary,engine='python')\n",
    "\n",
    "        eval_summary = eval_summary.fillna(0.5)\n",
    "\n",
    "        eval_summary['slope'] = np.abs(eval_summary['slope'])\n",
    "        eval_summary['intercept'] = np.abs(eval_summary['intercept'])\n",
    "       \n",
    "        All_metrics_available = ['slope', 'intercept','RMSE', 'RSC', 'R2', 'RMSECVQ1', 'RMSECVQ2', 'RMSECVQ3', 'RMSECVQ4','Accuracy','PCC1','PCC2','PCC3']\n",
    "        eval_summary_subset = eval_summary.copy()\n",
    "        metric_rank_dict = {}\n",
    "        list_models = []\n",
    "        print(chemical)\n",
    "#         print(eval_summary_subset)\n",
    "        if All_metrics == False:\n",
    "            working_metrics = working_metrics\n",
    "        else:\n",
    "            working_metrics = All_metrics_available\n",
    "        if chemical in ['clay','sand','calcium','silt','potassium','magnesium','aluminium','sodium','ec_salts','exchangeable_acidity','sulphur','copper']:\n",
    "            removed_metrics = ['Accuracy', 'recall_score', 'precision_score','f1_score','PCC1','PCC2','PCC3']\n",
    "            for metric in removed_metrics:\n",
    "                if metric in working_metrics: working_metrics.remove(metric)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            pass\n",
    "      \n",
    "        print('Subset is'   ,eval_summary_subset) \n",
    "        \n",
    "        for metric in working_metrics:\n",
    "            try:\n",
    "#                 eval_ = pivot_table(eval_summary_subset, values=metric, index=['Unnamed: 0'], columns=['Unnamed: 1'], aggfunc='sum')\n",
    "                eval_ = pivot_table(eval_summary_subset, values=metric, index=['index'], columns=['Model'], aggfunc='sum')\n",
    "            except:\n",
    "#                 eval_ = pivot_table(eval_summary_subset, values=metric, index=['index'], columns=['Model'], aggfunc='sum')\n",
    "                \n",
    "                eval_ = pivot_table(eval_summary_subset, values=metric, index=['Unnamed: 0'], columns=['Unnamed: 1'], aggfunc='sum')\n",
    "#             try:\n",
    "                \n",
    "                eval_, _ = self.conform_headers(eval_)\n",
    "                eval_ = eval_[(eval_.T != 0).any()]\n",
    "#             except:\n",
    "#                 pass\n",
    "\n",
    "            if metric in ['R2','RSC', 'recall_score','precision_score','f1_score','Accuracy','slope']:\n",
    "#                 print(eval_.T.sort_values(by = chemical, ascending=False)[chemical])\n",
    "                print(eval_.T)\n",
    "                list_models = eval_.T.sort_values(by = chemical, ascending=False)[chemical].index.tolist()\n",
    "            else:\n",
    "                list_models = eval_.T.sort_values(by = chemical, ascending=True)[chemical].index.tolist()\n",
    "                #dict with numerical index for different models available\n",
    "            list_models.extend(list_models)\n",
    "            \n",
    "            # remove duplicates from list\n",
    "            list_models = list(dict.fromkeys(list_models))\n",
    "#             print(list_models)\n",
    "            models_arranged_based_on_performance = dict([(y,x) for x,y in enumerate(list_models)])\n",
    "#             print(models_arranged_based_on_performance)\n",
    "            metric_rank_dict.update({metric:models_arranged_based_on_performance})\n",
    "#               \n",
    "# \n",
    "          \n",
    "            df_rank_models = pd.DataFrame(metric_rank_dict)   \n",
    "            best_model = pd.DataFrame(df_rank_models.sum(axis=1)).sort_values(by = [0]).head(1)\n",
    "\n",
    "                \n",
    "#             if aggregator == 'minimum':\n",
    "            \n",
    "#             else:\n",
    "#                 pass\n",
    "\n",
    "        return best_model\n",
    "    \n",
    "\n",
    "\n",
    "    def Different_Models_Eval(self, path_to_file,project_name, training_pred_score_paths=None,wet_chem_path=None ,predict=False, codes=None):\n",
    "    #         for training_pred_score_path in paths_to_models_summary_config:\n",
    "        df_dict = {}\n",
    "        list_ = []\n",
    "        with open(path_to_file, 'r') as fd:\n",
    "            reader = csv.reader(fd)\n",
    "            for row in reader:\n",
    "                list_.append(row)\n",
    "        for training_pred_score_path in list_:\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join(training_pred_score_path[0], 'saved_models', 'Evaluation_Summary','best_model.csv'))\n",
    "                df['modelling_type'] = training_pred_score_path[1]\n",
    "                df_dict.update({training_pred_score_path[1]: df})\n",
    "                self.Models_Summary(training_pred_score_path[0], project_name, working_metrics,training_pred_score_paths=None,wet_chem_path=None ,predict=False, codes=None)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        chemicals_conv = []\n",
    "        training_pred_score_path = list_[0][0]\n",
    "        path_to_saved_models =  os.path.join(training_pred_score_path, 'saved_models')\n",
    "        for i in range(len(os.listdir(path_to_saved_models))):\n",
    "            if os.listdir(path_to_saved_models)[i].endswith('False_y_pred_list_df.csv'):\n",
    "                chem_ = os.listdir(path_to_saved_models)[i].split('_')[0]\n",
    "                chem_ , _ = EvaluationTool().correct_chemical_name(chem_)\n",
    "                chemicals_conv.append(chem_)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "#             print(training_pred_score_path[0])\n",
    "\n",
    "        \n",
    "        df_5 = pd.concat([df_dict[k] for k , _ in df_dict.items() ])\n",
    "\n",
    "\n",
    "        df_5 = df_5.rename(columns = {'Unnamed: 0' : 'index', 'Unnamed: 1' : 'Model'})\n",
    "        new = df_5[\"modelling_type\"].copy() \n",
    "\n",
    "        df_5[\"Model\"]= df_5[\"Model\"].str.cat(new, sep =\", \") \n",
    "\n",
    "\n",
    "        All_metrics_available = ['slope', 'intercept','RMSE', 'RSC', 'R2', 'RMSECVQ1', 'RMSECVQ2', 'RMSECVQ3', 'RMSECVQ4','Accuracy', 'PCC1', 'PCC2', 'PCC3']\n",
    "#          'recall_score', 'precision_score','f1_score'\n",
    "        eval_summary_subset = df_5.copy()\n",
    "        eval_summary_subset = eval_summary_subset.fillna(0.5)\n",
    "        metric_rank_dict = {}\n",
    "        list_models = []\n",
    "        best_models = []\n",
    "        for chemical in chemicals_conv:\n",
    "            working_metrics = All_metrics_available\n",
    "            for metric in working_metrics:\n",
    "\n",
    "                eval_ = pivot_table(eval_summary_subset, values=metric, index=['index'], columns=['Model'], aggfunc='sum')\n",
    "                eval_, _ = self.conform_headers(eval_)\n",
    "                eval_ = eval_[(eval_.T != 0).any()]\n",
    "\n",
    "                if metric in ['R2','RSC']:\n",
    "#                     'recall_score','precision_score','f1_score'\n",
    "\n",
    "                    list_models = eval_.T.sort_values(by = chemical, ascending=False)[chemical].index.tolist()\n",
    "                else:\n",
    "                    list_models = eval_.T.sort_values(by = chemical, ascending=True)[chemical].index.tolist()\n",
    "                    #dict with numerical index for different models available\n",
    "                list_models.extend(list_models)\n",
    "                # remove duplicates from list\n",
    "                list_models = list(dict.fromkeys(list_models))\n",
    "\n",
    "                models_arranged_based_on_performance = dict([(y,x) for x,y in enumerate(list_models)])\n",
    "                metric_rank_dict.update({metric:models_arranged_based_on_performance})\n",
    "                df_rank_models = pd.DataFrame(metric_rank_dict)     \n",
    "            #             if aggregator == 'minimum':\n",
    "                best_model = pd.DataFrame(df_rank_models.sum(axis=1)).sort_values(by = [0]).head(1)\n",
    "            #       \n",
    "\n",
    "            best_models_comb_df = pd.DataFrame()\n",
    "            best_model_df = best_model.replace(best_model.iloc[0][0], chemical)\n",
    "            best_models_comb_df = pd.concat([best_models_comb_df, best_model_df])\n",
    "            best_models_comb_df = best_models_comb_df.rename(columns = {0: 'chemical'}).reset_index().rename(columns = {'index':'Model'}).set_index('chemical')\n",
    "            best_models.append(best_models_comb_df)\n",
    "            # path_to_evaluation_summary= os.path.join(path_to_save,'Evaluation_Summary_subset')\n",
    "\n",
    "\n",
    "        df_5 = df_5.set_index(['index','modelling_type'])\n",
    "        combined_best_ml = pd.DataFrame()\n",
    "        for index_no , chemical in enumerate(chemicals_conv):\n",
    "\n",
    "            df_7 = df_5.loc[(chemical ,best_models[index_no].Model.str.split(',')[0][1].strip('_'))].to_frame().T\n",
    "\n",
    "            combined_best_ml = pd.concat([combined_best_ml, df_7])\n",
    "#             os.makedirs(f'{os.getcwd()}_{project_name}', exist_ok=True)\n",
    "#             '/home/java/DS-RL22_Fritsch-grinding-plants/combined_best_model'\n",
    "            combined_best_ml.to_csv('/home/java/DS-RL22_Fritsch-grinding-plants/combined_best_model/best_models.csv')\n",
    "    def post_prediction_preds(self,training_pred_score_path,project_name,working_metrics,corrected_chems=None,chem_correction=None):\n",
    "        region = project_name\n",
    "        k_correction_formular = \"potassium_v1 if < 230 : potassium_prediction * 1.288076 + (-106.6364)\"\n",
    "        zn_correction_formular = \"zinc_v1: zinc_prediction - 2\"\n",
    "        phosphorus_correction = 'phosphorus_v3:  [<30, 30, 50, 80, > 80 ]'\n",
    "#         lines = [k_correction_formular, zn_correction_formular, phosphorus_correction]\n",
    "        lines = [k_correction_formular, phosphorus_correction]\n",
    "        source_path = training_pred_score_path\n",
    "        chem_correction = True\n",
    "        added_chemicals = ['calcium_%', 'potassium_%','magnesium_%']\n",
    "       \n",
    "     \n",
    "        chemicals_conv = []\n",
    "        path = os.path.join(training_pred_score_path ,'post_correction', )\n",
    "        os.makedirs(path,exist_ok=True)\n",
    "        path2 = os.path.join(training_pred_score_path ,'post_correction', 'saved_models' )\n",
    "        os.makedirs(path2,exist_ok=True)\n",
    "        path_to_saved_models =  os.path.join(training_pred_score_path, 'saved_models')\n",
    "        path_to_saved_models = Path(path_to_saved_models)\n",
    "        all_models_chems = [x for x in path_to_saved_models.glob('**/*False_y_pred_list_df.csv')]\n",
    "        \n",
    "        for models_chem in all_models_chems:\n",
    "            chem_ = models_chem.stem.split('_False')[0]\n",
    "            chemicals_conv.append(chem_)\n",
    "            \n",
    "            \n",
    "        all_chems = chemicals_conv\n",
    "        for chemical in chemicals_conv:\n",
    "            \n",
    "            if chemical in corrected_chems:\n",
    "                chem_map = EvaluationTool().get_chem_model_map(training_pred_score_path, chemical)\n",
    "                models = chem_map.get(chemical)\n",
    "                for idx, models_ in enumerate(chem_map.get(chemical)):\n",
    "                    print(idx , '+++++++++++++++++++++++++++++++++++++++++')\n",
    "                    model_first_name = models_\n",
    "\n",
    "                    \n",
    "                    print(f'+ + + + + + Starting Post prediction corection for {chemical} + + + + + + +')\n",
    "\n",
    "\n",
    "\n",
    "                    df = pd.read_csv(os.path.join(training_pred_score_path , 'saved_models/',f'{chemical}_False_y_pred_list_df.csv'),index_col=0)\n",
    "                    if chemical == 'zinc':\n",
    "\n",
    "                        if idx == 0:\n",
    "                            comb_df_corrected = self.zinc_correction(df, models)\n",
    "                            comb_df_corrected.to_csv(os.path.join(path,'saved_models/',f'{chemical}_False_y_pred_list_df.csv'))\n",
    "                            comb_df_corrected.to_pickle(os.path.join(path ,'saved_models/',f'{chemical}_{model_first_name}_regression_False_score_trained.pkl'))\n",
    "                        else:\n",
    "                            comb_df_corrected = pd.DataFrame()\n",
    "\n",
    "                        comb_df_corrected.to_pickle(os.path.join(path ,'saved_models/',f'{chemical}_{model_first_name}_regression_False_score_trained.pkl'))\n",
    "                    elif chemical == 'potassium' :\n",
    "\n",
    "#                         source = os.path.join(source_path ,'saved_models','cec_False_y_pred_list_df.csv')\n",
    "#                         shutil.copy2(source,os.path.join(path,'saved_models/','cec_False_y_pred_list_df.csv'))\n",
    "                        print(f'running {chemical} post-correction')\n",
    "                        if idx == 0:\n",
    "\n",
    "                            comb_df_corrected = self.potassium_correction(df, models)\n",
    "                            comb_df_corrected.to_csv(os.path.join(path,'saved_models/',f'{chemical}_False_y_pred_list_df.csv'))\n",
    "#                             comb_df_corrected.to_pickle(os.path.join(path ,'saved_models/',f'cec_{model_first_name}_regression_False_score_trained.pkl'))\n",
    "#                             EvaluationTool().chem_to_percentage_conversion(path,corrected_chems)\n",
    "                            \n",
    "                        else:\n",
    "                            comb_df_corrected = pd.DataFrame()\n",
    "\n",
    "#                                  \n",
    "                        comb_df_corrected.to_pickle(os.path.join(path ,'saved_models/',f'{chemical}_{model_first_name}_regression_False_score_trained.pkl'))\n",
    "#                         comb_df_corrected.to_pickle(os.path.join(path ,'saved_models/',f'cec_{model_first_name}_regression_False_score_trained.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#                                 else:\n",
    "#                                     pass\n",
    "                    elif chemical =='phosphorus':\n",
    "                        source = os.path.join(source_path ,'saved_models',f'{chemical}_False_y_pred_list_df.csv')\n",
    "                        shutil.copy2(source,os.path.join(path,'saved_models/',f'{chemical}_False_y_pred_list_df.csv'))\n",
    "                        df.to_pickle(os.path.join(path ,'saved_models/',f'{chemical}_{model_first_name}_regression_False_score_trained.pkl'))\n",
    "\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        with open(os.path.join(path2, 'post_prediction_rules.txt') , 'w') as f:\n",
    "            for line in lines:\n",
    "                f.write(line)\n",
    "                f.write('\\n')\n",
    "\n",
    "\n",
    "            \n",
    "        self.Models_Summary(path,project_name, working_metrics,chem_correction,corrected_chems)\n",
    "        \n",
    "        best_models_comb_df = pd.DataFrame()\n",
    "#         chemicals_conv.extend(added_chemicals)\n",
    "        path_to_evaluation_non_corr= os.path.join(training_pred_score_path,'saved_models','Evaluation_Summary', f'best_model.csv')\n",
    "        path_to_evaluation_corr= os.path.join(path2,'Evaluation_Summary', f'best_model.csv')\n",
    "        df_corr = pd.read_csv(path_to_evaluation_corr)\n",
    "        df_corr = df_corr.rename(columns = {'Unnamed: 1' : 'Model', 'Unnamed: 0': 'index'})\n",
    "        df_corr['Model'] = [df_corr['Model'][x] + '_corrected' for x in range(df_corr.shape[0])]\n",
    "        df_corr = df_corr.set_index(['index','Model'])\n",
    "        df_non_corr = pd.read_csv(path_to_evaluation_non_corr,index_col=[0,1])\n",
    "        df_comb_corr_non = pd.concat([df_corr,df_non_corr])\n",
    "        df_comb_corr_non.to_csv(os.path.join(path2, 'best_model.csv'))\n",
    "        df_comb_corr_non.to_csv(os.path.join(path2, f'Evaluation_{region}.csv'))\n",
    "        \n",
    "        \n",
    "        \n",
    "        path_to_evaluation_summary= os.path.join(path2,'best_model.csv')\n",
    "#         for chem in all_chems:\n",
    "#             if 'calcium' == chem:\n",
    "#                 chem = 'calcium_%'\n",
    "#                 all_chems.append(chem)\n",
    "#             elif 'potassium' == chem:\n",
    "#                 chem = 'potassium_%'\n",
    "#                 all_chems.append(chem)\n",
    "#             elif 'magnesium' == chem:\n",
    "#                 chem = 'magnesium_%'\n",
    "#                 all_chems.append(chem)\n",
    "                \n",
    "       \n",
    "        for chemical in all_chems:\n",
    "            try:\n",
    "                print('Printing is +++++++++++++++++++++++++++++++++++++++++', chemical)\n",
    "\n",
    "\n",
    "\n",
    "                best_model = self.BestModelSelectorPerChem(path_to_evaluation_summary=path_to_evaluation_summary, chemical=chemical,working_metrics=working_metrics)\n",
    "                best_model_df = best_model.replace(best_model.iloc[0][0], chemical)\n",
    "                best_models_comb_df = pd.concat([best_models_comb_df, best_model_df])\n",
    "              \n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "                #             except Exception as e:\n",
    "            #                 print(f'{chemical} fails with exception {e}')\n",
    "            #                 pass\n",
    "    #         print(best_models_comb_df)\n",
    "        \n",
    "        best_models_comb_df = best_models_comb_df.rename(columns = {0: 'chemical'}).reset_index().rename(columns = {'index':'Model'}).set_index('chemical')\n",
    "        \n",
    "\n",
    "\n",
    "                \n",
    "#         path_to_evaluation_summary= os.path.join(path_to_save)\n",
    "        best_models_comb_df.to_csv(os.path.join(path2 , 'best_model_2.csv'))\n",
    "\n",
    "        best_models = pd.read_csv(os.path.join(path2 , 'best_model_2.csv'), index_col = [0,1])\n",
    "        path_to_evaluation_summary= os.path.join(path2, f'Evaluation_{region}.csv')\n",
    "        evaluation_summary = pd.read_csv(path_to_evaluation_summary, index_col=[0,1])\n",
    "\n",
    "        comb_df = pd.DataFrame()\n",
    "        os.makedirs(os.path.join(path_to_saved_models, 'best_models'),exist_ok=True)\n",
    "        path_to_save = os.path.join(path_to_saved_models, 'best_models')\n",
    "        for best in range(len(best_models)):\n",
    "            tup_chem_ml = best_models.iloc[best].name\n",
    "#             try:\n",
    "            evaluation_summary_2 = evaluation_summary.loc[tup_chem_ml].to_frame().T\n",
    "#                 return evaluation_summary_2\n",
    "#             except:\n",
    "#                 evaluation_summary_2 = evaluation_summary.loc[tup_chem_ml]\n",
    "#                 return evaluation_summary_2\n",
    "#             evaluation_summary_2 = evaluation_summary_2.reset_index()\n",
    "            comb_df = pd.concat([comb_df,evaluation_summary_2])\n",
    "            path_to_evaluation_summary= os.path.join(path_to_save)\n",
    "        #                 comb_df=comb_df.drop_duplicates()\n",
    "        #     if corrected_chems:\n",
    "        #         comb_df['corrected'] = True\n",
    "        #     else:\n",
    "\n",
    "        #         comb_df['corrected'] = False\n",
    "            comb_df = comb_df.drop_duplicates()\n",
    "            comb_df.to_csv(os.path.join(path_to_evaluation_summary , 'best_model.csv'))\n",
    "    def zinc_correction(self, df, models):\n",
    "        df_y_true_val = df['y_true_val'].to_frame()\n",
    "        comb_df_corrected = pd.DataFrame()\n",
    "\n",
    "    #     print(f'running {chemical} post-correction')\n",
    "        for model_first_name in models:\n",
    "            for index in df.index:\n",
    "                print(model_first_name)\n",
    "                zn_pred = df.at[index,f'{model_first_name}_regression']\n",
    "                print(f'subtracting 2...')\n",
    "                zn_pred_corrected = zn_pred - 2\n",
    "                print(f'replacing {zn_pred} with {zn_pred_corrected}')\n",
    "                df.at[index,f'{model_first_name}_regression'] = zn_pred_corrected\n",
    "\n",
    "                print('done')\n",
    "            df_ = df[f'{model_first_name}_regression'].to_frame()\n",
    "            comb_df_corrected = pd.concat([comb_df_corrected, df_],axis=1)\n",
    "        comb_df_corrected = pd.concat([comb_df_corrected, df_y_true_val],axis=1)\n",
    "        return comb_df_corrected\n",
    "\n",
    "    def potassium_correction(self, df, models):\n",
    "        models = list(dict.fromkeys(models))\n",
    "        df_y_true_val = df['y_true_val'].to_frame()\n",
    "        comb_df_corrected = pd.DataFrame()\n",
    "        chemical = 'potassium'\n",
    "    #     print(f'running {chemical} post-correction')\n",
    "        for model_first_name in models:\n",
    "            for index in df.index:\n",
    "                k_pred = df.at[index,f'{model_first_name}_regression']\n",
    "                if k_pred < 230:\n",
    "                    print(f'{chemical} prediction less than 230, correcting...')\n",
    "                    k_pred_corrected = k_pred *1.288076+(-106.6364)\n",
    "                    print(f'replacing {k_pred} with {k_pred_corrected}')\n",
    "                    df.at[index,f'{model_first_name}_regression'] = k_pred_corrected\n",
    "                    print('done')\n",
    "            df_ = df[f'{model_first_name}_regression'].to_frame()\n",
    "            comb_df_corrected = pd.concat([comb_df_corrected, df_],axis=1)\n",
    "        comb_df_corrected = pd.concat([comb_df_corrected, df_y_true_val],axis=1)\n",
    "        return comb_df_corrected\n",
    "    def ModelsSummaryStats(self, training_pred_score_path, project_name, working_metrics,corrected_chems=None,chem_correction=None,training_pred_score_paths=None,wet_chem_path=None ,predict=False, codes=None):\n",
    "        \n",
    "        \n",
    "        self.Models_Summary(training_pred_score_path, project_name, working_metrics,corrected_chems=False)\n",
    "\n",
    "        df = self.post_prediction_preds(training_pred_score_path,project_name,working_metrics,corrected_chems,chem_correction=True)\n",
    "        folders = ['Evaluation_Summary', 'Predictions','confusion_matrix','scatter_plots']\n",
    "             \n",
    "        today = date.today()\n",
    "\n",
    "        d1 = today.strftime(\"%Y/%m/%d\")\n",
    "        d1 = d1.replace('/','_')\n",
    "#         os.makedirs(os.path.join(training_pred_score_path,f'{d1}_{project_name}_v2.0_v2.2_v5'),exist_ok=True)\n",
    "#                 os.makedirs(os.path.join(training_pred_score_path,f'{d1}_{project_name}_v2.0_v2.2_v5'),exist_ok=True)\n",
    "        final_folder = os.path.join(training_pred_score_path,f'{d1}_{project_name}_v2.0_v2.2_v5','post_correction')\n",
    "        os.makedirs(final_folder,exist_ok=True)  \n",
    "             \n",
    "        path_to_save  = os.path.join(training_pred_score_path ,'post_correction','saved_models')\n",
    "        post_prediction_rules_path  = os.path.join(training_pred_score_path ,'post_correction','saved_models','post_prediction_rules.txt')\n",
    "        \n",
    "        for folder in folders:\n",
    "\n",
    "#                 copy_tree(os.path.join(path_to_save, folder), final_folder)\n",
    "\n",
    "            current_folder = os.path.join(path_to_save, folder)\n",
    "            !cp -r {current_folder} {final_folder}\n",
    "        best_models_folder = os.path.join(training_pred_score_path,'saved_models','best_models')\n",
    "        final_folder_models = os.path.join(training_pred_score_path,f'{d1}_{project_name}_v2.0_v2.2_v5')\n",
    "        !cp -r {best_models_folder } {final_folder_models}\n",
    "        shutil.copy2(post_prediction_rules_path,final_folder )\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556fab8b",
   "metadata": {},
   "source": [
    "# Cleaning wetchem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d02b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in wetchem_df.columns:\n",
    "    if(column != 'sample_code'):\n",
    "        vals = []\n",
    "        for value in wetchem_df[column].values:\n",
    "            if(value is not None):\n",
    "                value = str(value)\n",
    "                value = value.replace(\">\",\"\").replace(\"<\",\"\").replace(\"...\",\"\").strip()\n",
    "                value = float(value)\n",
    "            vals.append(value)\n",
    "        uncleaned_wetchem_df[column] = vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e6c0aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction using model version DLv2.3\n",
      "exchangeable_acidity\n",
      "Finalizing prediction using model version DLv2.3\n",
      "Starting to join predictions and wetchem for evaluation for model version DLv2.3\n",
      "Prediction folder path D:\\CropNutsDocuments\\DS-ML87\\outputFiles\\data\\preds\n",
      "Preds                     1\n",
      "sample_code          \n",
      "CA001SA0018  1.135085\n",
      "CA001SA0019  0.697873\n",
      "CA001SA0020  0.639065\n",
      "CA001SA0021  0.624931\n",
      "CA001SA0022  1.692417\n",
      "...               ...\n",
      "CW017SA7133  0.082512\n",
      "CW017SA7134  0.182488\n",
      "CW017SA7135  0.128159\n",
      "CW017SA7166  0.462965\n",
      "CY001SA0087  0.709431\n",
      "\n",
      "[12057 rows x 1 columns]\n",
      "Preds                     1\n",
      "sample_code          \n",
      "CA001SA0018  1.135085\n",
      "CA001SA0019  0.697873\n",
      "CA001SA0020  0.639065\n",
      "CA001SA0021  0.624931\n",
      "CA001SA0022  1.692417\n",
      "...               ...\n",
      "CW017SA7133  0.082512\n",
      "CW017SA7134  0.182488\n",
      "CW017SA7135  0.128159\n",
      "CW017SA7166  0.462965\n",
      "CY001SA0087  0.709431\n",
      "\n",
      "[12057 rows x 1 columns]\n",
      "Wet              y_true_val\n",
      "sample_code            \n",
      "CA001SA0018       1.050\n",
      "CA001SA0019       0.700\n",
      "CA001SA0020       0.900\n",
      "CA001SA0021       1.750\n",
      "CA001SA0022       2.200\n",
      "...                 ...\n",
      "CW017SA7133       0.046\n",
      "CW017SA7134       0.046\n",
      "CW017SA7135       0.092\n",
      "CW017SA7166       1.270\n",
      "CY001SA0087       1.600\n",
      "\n",
      "[12057 rows x 1 columns]\n",
      "(12057, 2)\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\aluminium.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\boron.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\calcium.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\cec.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\clay.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\copper.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\ec_salts.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\exchangeable_acidity.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\iron.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\magnesium.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\manganese.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\organic_carbon.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\ph.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\phosphorus.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\potassium.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\sand.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\silt.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\sodium.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\sulphur.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\total_nitrogen.csv\n",
      "D://CropNutsDocuments/DS-ML87/outputFiles/preds\\zinc.csv\n",
      "['aluminium.csv', 'boron.csv', 'calcium.csv', 'cec.csv', 'clay.csv', 'copper.csv', 'ec_salts.csv', 'exchangeable_acidity.csv', 'iron.csv', 'magnesium.csv', 'manganese.csv', 'organic_carbon.csv', 'ph.csv', 'phosphorus.csv', 'potassium.csv', 'sand.csv', 'silt.csv', 'sodium.csv', 'sulphur.csv', 'total_nitrogen.csv', 'zinc.csv']\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Model'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\CropNutsDocuments\\Eval_tool_plus_example\\EvaluationToolV5.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m delete_files(training_pred_score_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# project_name = 'v2.0-v2.2'\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m df \u001b[39m=\u001b[39m Models_Summary\u001b[39m.\u001b[39;49mModelsSummaryStats(training_pred_score_path,\u001b[39m'\u001b[39;49m\u001b[39mOCP_NG\u001b[39;49m\u001b[39m'\u001b[39;49m, working_metrics,corrected_chems\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mzinc\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mpotassium\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mphosphorus\u001b[39;49m\u001b[39m'\u001b[39;49m],chem_correction\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, predict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# 2021-x-x_v2.0-v2.2_v2.0-v2.2_v5.1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m project_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mv2.2\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;32md:\\CropNutsDocuments\\Eval_tool_plus_example\\EvaluationToolV5.ipynb Cell 18\u001b[0m in \u001b[0;36mModels_Summary.ModelsSummaryStats\u001b[1;34m(self, training_pred_score_path, project_name, working_metrics, corrected_chems, chem_correction, training_pred_score_paths, wet_chem_path, predict, codes)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=835'>836</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mModelsSummaryStats\u001b[39m(\u001b[39mself\u001b[39m, training_pred_score_path, project_name, working_metrics,corrected_chems\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,chem_correction\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,training_pred_score_paths\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,wet_chem_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m ,predict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, codes\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=838'>839</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mModels_Summary(training_pred_score_path, project_name, working_metrics,corrected_chems\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=840'>841</a>\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_prediction_preds(training_pred_score_path,project_name,working_metrics,corrected_chems,chem_correction\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=841'>842</a>\u001b[0m     folders \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mEvaluation_Summary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPredictions\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mconfusion_matrix\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mscatter_plots\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;32md:\\CropNutsDocuments\\Eval_tool_plus_example\\EvaluationToolV5.ipynb Cell 18\u001b[0m in \u001b[0;36mModels_Summary.Models_Summary\u001b[1;34m(self, training_pred_score_path, project_name, working_metrics, corrected_chems, chem_correction, training_pred_score_paths, wet_chem_path, predict, codes)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m     df_2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path_to_save,\u001b[39m'\u001b[39m\u001b[39mEvaluation_Summary\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEvaluation_\u001b[39m\u001b[39m{\u001b[39;00mregion\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m'\u001b[39m), index_col \u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m     \u001b[39mprint\u001b[39m(df_2)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=187'>188</a>\u001b[0m     df_2 \u001b[39m=\u001b[39m df_2\u001b[39m.\u001b[39;49mreset_index()\u001b[39m.\u001b[39;49mset_index([\u001b[39m'\u001b[39;49m\u001b[39mindex\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mModel\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=188'>189</a>\u001b[0m     df_2_copy \u001b[39m=\u001b[39m df_2\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/CropNutsDocuments/Eval_tool_plus_example/EvaluationToolV5.ipynb#X54sZmlsZQ%3D%3D?line=189'>190</a>\u001b[0m list_of_models \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:5500\u001b[0m, in \u001b[0;36mDataFrame.set_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5497\u001b[0m                 missing\u001b[39m.\u001b[39mappend(col)\n\u001b[0;32m   5499\u001b[0m \u001b[39mif\u001b[39;00m missing:\n\u001b[1;32m-> 5500\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of \u001b[39m\u001b[39m{\u001b[39;00mmissing\u001b[39m}\u001b[39;00m\u001b[39m are in the columns\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5502\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   5503\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Model'] are in the columns\""
     ]
    }
   ],
   "source": [
    "#v2.0 v2.2\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "Models_Summary = Models_Summary()\n",
    "# chemicals = ['magnesium','zinc', 'manganese', 'sodium', 'potassium', 'sulphur', 'calcium','ph', 'phosphorus', 'clay', 'sand', 'silt', 'aluminium', 'boron', 'copper','iron']\n",
    "chemicals = ['exchangeable_acidity']\n",
    "\n",
    "path_to_spectra = 'D://CropNutsDocuments/DS-ML87/outputFiles/data/spc/spc.csv'\n",
    "\n",
    "path_to_wet = 'D://CropNutsDocuments/DS-ML87/outputFiles/data/wetchem/wetchem.csv'\n",
    "predction_folder_path = Path('D://CropNutsDocuments/DS-ML87/outputFiles/data/preds')\n",
    "# model_versions = ['DLv2.0','DLv2.2']\n",
    "model_versions = ['DLv2.3']\n",
    "\n",
    "path_to_model = 'D://CropNutsDocuments/DS-ML87/outputFiles/exchangeable_acidity_20230502_090639.071097'\n",
    "output_path = 'D://CropNutsDocuments/DS-ML87/outputFiles/data/preds'\n",
    "predict_chems(path_to_model,predction_folder_path, chemicals,model_versions, pd.read_csv(path_to_spectra, engine='c', index_col=0))\n",
    "post_pred_version_per_chem = {'potassium': 'v1', 'phosphorus' : 'v3','zinc':'v1'}\n",
    "paths = [path_to_spectra]\n",
    "\n",
    "# join_diff_models_data(output_path ,model_versions, chemicals, \"OCP_NG\")\n",
    "join_preds_wet(path_to_wet, output_path ,model_versions, chemicals, predction_folder_path)\n",
    "working_metrics = ['slope', 'intercept','RMSE', 'RSC', 'R2', 'RMSECVQ1', 'RMSECVQ2', 'RMSECVQ3', 'RMSECVQ4','Accuracy','PCC1','PCC2','PCC3']\n",
    "# 'recall_score', 'precision_score','f1_score'\n",
    "from pandas import pivot_table\n",
    "training_pred_score_path = 'D://CropNutsDocuments/DS-ML87/outputFiles/preds'\n",
    "lines = [chemicals , path_to_spectra, path_to_wet,predction_folder_path,model_versions,path_to_model,output_path, post_pred_version_per_chem, paths,working_metrics]\n",
    "delete_files(training_pred_score_path)\n",
    "# project_name = 'v2.0-v2.2'\n",
    "df = Models_Summary.ModelsSummaryStats(training_pred_score_path,'OCP_NG', working_metrics,corrected_chems=['zinc','potassium','phosphorus'],chem_correction=True, predict=True)\n",
    "\n",
    "# 2021-x-x_v2.0-v2.2_v2.0-v2.2_v5.1\n",
    "\n",
    "project_name = 'v2.2'\n",
    "lines_dict = {0 :'chemicals', 1 : 'path_to_spectra', 2: 'path_to_wet', 3:\"prediction_folder_path\" ,4 :\"model_versions\", 5:\"path_to_model\",6:\"output_path\" , 7 : \"post_pred_version_per_chem\", 8:\"paths\" , 9 :'working_metrics'}\n",
    "delete_uneccessay_files(training_pred_score_path)\n",
    "saved_eval_params(training_pred_score_path,project_name, lines,lines_dict)\n",
    "\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a2d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718ac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f76630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
